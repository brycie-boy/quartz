<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="14
1
Missing Data
14
Before we get going, we need to establish one thing beyond any doubt: industry-funded trials are more likely to produce a positive, flattering result than independently-funded trials."><meta property="og:title" content><meta property="og:description" content="14
1
Missing Data
14
Before we get going, we need to establish one thing beyond any doubt: industry-funded trials are more likely to produce a positive, flattering result than independently-funded trials."><meta property="og:type" content="website"><meta property="og:image" content="https://thecosmos.brycemcalister.comicon.png"><meta property="og:url" content="https://thecosmos.brycemcalister.com/Inbox-scrap-31/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="14
1
Missing Data
14
Before we get going, we need to establish one thing beyond any doubt: industry-funded trials are more likely to produce a positive, flattering result than independently-funded trials."><meta name=twitter:image content="https://thecosmos.brycemcalister.comicon.png"><title>🔮 The Cosmos</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://thecosmos.brycemcalister.com/icon.png><link href=https://thecosmos.brycemcalister.com/styles.80e54ad3e0ca8043bc5106707ddfa108.min.css rel=stylesheet><link href=https://thecosmos.brycemcalister.com/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://thecosmos.brycemcalister.com/js/darkmode.b3be288da0f5e2b47c1c3b23f47d6c25.min.js></script>
<script src=https://thecosmos.brycemcalister.com/js/util.00639692264b21bc3ee219733d38a8be.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script defer src=https://thecosmos.brycemcalister.com/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://thecosmos.brycemcalister.com/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://thecosmos.brycemcalister.com/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://thecosmos.brycemcalister.com/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://thecosmos.brycemcalister.com",fetchData=Promise.all([fetch("https://thecosmos.brycemcalister.com/indices/linkIndex.dc14971b6f5291ca13a96d34171da326.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://thecosmos.brycemcalister.com/indices/contentIndex.0eae5ec55333782ec6f69cb1645a0606.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://thecosmos.brycemcalister.com",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://thecosmos.brycemcalister.com",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/thecosmos.brycemcalister.com\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=thecosmos.brycemcalister.com src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://thecosmos.brycemcalister.com/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://thecosmos.brycemcalister.com>🔮 The Cosmos</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Unknown
<a href=https://github.com/brycie-boy/quartz/Inbox%20scrap%2031.md rel=noopener>Edit Source</a></p><ul class=tags></ul><p>14</p><p>1</p><p>Missing Data</p><p>14</p><p>Before we get going, we need to establish one thing beyond any doubt: industry-funded trials are more likely to produce a positive, flattering result than independently-funded trials. This is our core premise, and you’re about to read a very short chapter, because this is one of the most well-documented phenomena in the growing field of ‘research about research’. It has also become much easier to study in recent years, because the rules on declaring industry funding have become a little clearer.</p><p>14</p><p>We can begin with some recent work: in 2010, three researchers from Harvard and Toronto found all the trials looking at five major classes of drug – antidepressants, ulcer drugs and so on – then measured two key features: were they positive, and were they funded by industry?1 They found over five hundred trials in total: 85 per cent of the industry-funded studies were positive, but only 50 per cent of the government-funded trials were. That’s a very significant difference.</p><p>429</p><p>1 Bourgeois FT, Murthy S, Mandl KD. Outcome Reporting Among Drug Trials Registered in ClinicalTrials.gov. Annals of Internal Medicine. 2010;153(3):158–66.</p><p>14</p><p>In 2007, researchers looked at every published trial that set out to explore the benefit of a statin.2 These are cholesterol-lowering drugs which reduce your risk of having a heart attack, they are prescribed in very large quantities, and they will loom large in this book. This study found 192 trials in total, either comparing one statin against another, or comparing a statin against a different kind of treatment. Once the researchers controlled for other factors (we’ll delve into what this means later), they found that industry-funded trials were twenty times more likely to give results favouring the test drug. Again, that’s a very big difference.</p><p>429</p><p>2 Bero L, Oostvogel F, Bacchetti P, Lee K. Factors Associated with Findings of Published Trials of Drug–Drug Comparisons: Why Some Statins Appear More Efficacious than Others. PLoS Med. 2007 Jun 5;4(6):e184.</p><p>15</p><p>We’ll do one more. In 2006, researchers looked into every trial of psychiatric drugs in four academic journals over a ten-year period, finding 542 trial outcomes in total. Industry sponsors got favourable outcomes for their own drug 78 per cent of the time, while independently-funded trials only gave a positive result in 48 per cent of cases. If you were a competing drug put up against the sponsor’s drug in a trial, you were in for a pretty rough ride: you would only win a measly 28 per cent of the time.3</p><p>429</p><p>3 Kelly RE Jr, Cohen LJ, Semple RJ, Bialer P, Lau A, Bodenheimer A, et al. Relationship between drug company funding and outcomes of clinical psychiatric research. Psychol Med. 2006 Nov;36(11):1647–56.</p><p>15</p><p>These are dismal, frightening results, but they come from individual studies. When there has been lots of research in a field, it’s always possible that someone – like me, for example – could cherry-pick the results, and give a partial view. I could, in essence, be doing exactly what I accuse the pharmaceutical industry of doing, and only telling you about the studies that support my case, while hiding the reassuring ones from you.</p><p>15</p><p>To guard against this risk, researchers invented the systematic review. We’ll explore this in more detail soon, since it’s at the core of modern medicine, but in essence a systematic review is simple: instead of just mooching through the research literature, consciously or unconsciously picking out papers here and there that support your pre-existing beliefs, you take a scientific, systematic approach to the very process of looking for scientific evidence, ensuring that your evidence is as complete and representative as possible of all the research that has ever been done.</p><p>16</p><p>Systematic reviews are very, very onerous. In 2003, by coincidence, two were published, both looking specifically at the question we’re interested in. They took all the studies ever published that looked at whether industry funding is associated with pro-industry results. Each took a slightly different approach to finding research papers, and both found that industry-funded trials were, overall, about four times more likely to report positive results.4 A further review in 2007 looked at the new studies that had been published in the four years after these two earlier reviews: it found twenty more pieces of work, and all but two showed that industry-sponsored trials were more likely to report flattering results.5</p><p>429</p><p>5 Sergio S. Pharmaceutical company funding and its consequences: A qualitative systematic review. Contemporary Clinical Trials. 2008 Mar;29(2):109–13.</p><p>16</p><p>I am setting out this evidence at length because I want to be absolutely clear that there is no doubt on the issue. Industry-sponsored trials give favourable results, and that is not my opinion, or a hunch from the occasional passing study. This is a very well-documented problem, and it has been researched extensively, without anybody stepping out to take effective action, as we shall see.</p><p>16</p><p>There is one last study I’d like to tell you about. It turns out that this pattern of industry-funded trials being vastly more likely to give positive results persists even when you move away from published academic papers, and look instead at trial reports from academic conferences, where data often appears for the first time (in fact, as we shall see, sometimes trial results only appear at an academic conference, with very little information on how the study was conducted).</p><p>17</p><p>Fries and Krishnan studied all the research abstracts presented at the 2001 American College of Rheumatology meetings which reported any kind of trial, and acknowledged industry sponsorship, in order to find out what proportion had results that favoured the sponsor’s drug. There is a small punch-line coming, and to understand it we need to cover a little of what an academic paper looks like. In general, the results section is extensive: the raw numbers are given for each outcome, and for each possible causal factor, but not just as raw figures. The ‘ranges’ are given, subgroups are perhaps explored, statistical tests are conducted, and each detail of the result is described in table form, and in shorter narrative form in the text, explaining the most important results. This lengthy process is usually spread over several pages.</p><p>17</p><p>In Fries and Krishnan [2004] this level of detail was unnecessary. The results section is a single, simple, and – I like to imagine – fairly passive-aggressive sentence:</p><p>The results from every RCT (45 out of 45) favored the drug of the sponsor.</p><p>17</p><p>This extreme finding has a very interesting side effect, for those interested in time-saving shortcuts. Since every industry-sponsored trial had a positive result, that’s all you’d need to know about a piece of work to predict its outcome: if it was funded by industry, you could know with absolute certainty that the trial found the drug was great.</p><p>18</p><p>How does this happen? How do industry-sponsored trials almost always manage to get a positive result? It is, as far as anyone can be certain, a combination of factors. Sometimes trials are flawed by design. You can compare your new drug with something you know to be rubbish – an existing drug at an inadequate dose, perhaps, or a placebo sugar pill that does almost nothing. You can choose your patients very carefully, so they are more likely to get better on your treatment. You can peek at the results halfway through, and stop your trial early if they look good (which is – for interesting reasons we shall discuss – statistical poison). And so on.</p><p>18</p><p>But before we get to these fascinating methodological twists and quirks, these nudges and bumps that stop a trial from being a fair test of whether a treatment works or not, there is something very much simpler at hand.</p><p>Sometimes drug companies conduct lots of trials, and when they see that the results are unflattering, they simply fail to publish them. This is not a new problem, and it’s not limited to medicine. In fact, this issue of negative results that go missing in action cuts into almost every corner of science. It distorts findings in fields as diverse as brain imaging and economics, it makes a mockery of all our efforts to exclude bias from our studies, and despite everything that regulators, drug companies and even some academics will tell you, it is a problem that has been left unfixed for decades.</p><p>18</p><p>In fact, it is so deep-rooted that even if we fixed it today – right now, for good, forever, without any flaws or loopholes in our legislation – that still wouldn’t help, because we would still be practising medicine, cheerfully making decisions about which treatment is best, on the basis of decades of medical evidence which is – as you’ve now seen – fundamentally distorted.</p><p>But there is a way ahead.</p><p>19</p><p>antidepressant</p><p>19</p><p>In October 2010 a group of researchers were finally able to bring together all the trials that had ever been conducted on reboxetine.6 Through a long process of investigation – searching in academic journals, but also arduously requesting data from the manufacturers and gathering documents from regulators – they were able to assemble all the data, both from trials that were published, and from those that had never appeared in academic papers.</p><p>429</p><p>6 Eyding D, Lelgemann M, Grouven U, Harter M, Kromp M, Kaiser T, et al. Reboxetine for acute treatment of major depression: systematic review and meta-analysis of published and unpublished placebo and selective serotonin reuptake inhibitor controlled trials. BMJ. 2010 Oct 12;341:c4737–c4737.</p><p>19</p><p>When all this trial data was put together it produced a shocking picture. Seven trials had been conducted comparing reboxetine against placebo. Only one, conducted in 254 patients, had a neat, positive result, and that one was published in an academic journal, for doctors and researchers to read. But six more trials were conducted, in almost ten times as many patients. All of them showed that reboxetine was no better than a dummy sugar pill. None of these trials was published.</p><p>20</p><p>It got worse. The trials comparing reboxetine against other drugs showed exactly the same picture: three small studies, 507 patients in total, showed that reboxetine was just as good as any other drug. They were all published. But 1,657 patients’ worth of data was left unpublished, and this unpublished data showed that patients on reboxetine did worse than those on other drugs. If all this wasn’t bad enough, there was also the side-effects data. The drug looked fine in the trials which appeared in the academic literature: but when we saw the unpublished studies, it turned out that patients were more likely to have side effects, more likely to drop out of taking the drug, and more likely to withdraw from the trial because of side effects, if they were taking reboxetine rather than one of its competitors.</p><p>21</p><p>‘publication bias’ – the process whereby negative results go unpublished</p><p>21</p><p>Researchers are free to do as many trials as they wish, and then choose which ones to publish.</p><p>21</p><p>The repercussions of this go way beyond simply misleading doctors about the benefits and harms of interventions for patients, and way beyond trials. Medical research isn’t an abstract academic pursuit: it’s about people, so every time we fail to publish a piece of research we expose real, living people to unnecessary, avoidable suffering.</p><p>22</p><p>In March 2006, six volunteers arrived at a London hospital to take place in a trial. It was the first time a new drug called TGN1412 had ever been given to humans, and they were paid £2,000 each.7 Within an hour these six men developed headaches, muscle aches, and a feeling of unease. Then things got worse: high temperatures, restlessness, periods of forgetting who and where they were. Soon they were shivering, flushed, their pulses racing, their blood pressure falling. Then, a cliff: one went into respiratory failure, the oxygen levels in his blood falling rapidly as his lungs filled with fluid. Nobody knew why. Another dropped his blood pressure to just 65/40, stopped breathing properly, and was rushed to an intensive care unit, knocked out, intubated, mechanically ventilated. Within a day all six were disastrously unwell: fluid on their lungs, struggling to breathe, their kidneys failing, their blood clotting uncontrollably throughout their bodies, and their white blood cells disappearing. Doctors threw everything they could at them: steroids, anti-histamines, immune-system receptor blockers. All six were ventilated on intensive care. They stopped producing urine; they were all put on dialysis; their blood was replaced, first slowly, then rapidly; they needed plasma, red cells, platelets. The fevers continued. One developed pneumonia. And then the blood stopped getting to their peripheries. Their fingers and toes went flushed, then brown, then black, and then began to rot and die. With heroic effort, all escaped, at least, with their lives.</p><p>429</p><p>7 Suntharalingam G, Perry MR, Ward S, Brett SJ, Castello-Cortes A, Brunner MD, et al. Cytokine storm in a phase 1 trial of the anti-CD28 monoclonal antibody TGN1412. N. Engl. J. Med. 2006 Sep 7;355(10):1018–28.</p><p>23</p><p>The Department of Health convened an Expert Scientific Group to try to understand what had happened, and from this two concerns were raised.8 Firstly: can we stop things like this from happening again? It’s plainly foolish, for example, to give a new experimental treatment to all six participants in a ‘first-inman’ trial at the same time, if that treatment is a completely unknown quantity. New drugs should be given to participants in a staggered process, slowly, over a day. This idea received considerable attention from regulators and the media.</p><p>429</p><p>8 Expert Group on Phase One Clinical Trials: Final report [Internet]. 2006 [cited 2012 Apr 5]. Available from:
<a href=http://www.dh.gov.uk/en/Publicationsandstatistics/Publications/PublicationsPolicyAndGuidance/DH_063117 rel=noopener>http://www.dh.gov.uk/en/Publicationsandstatistics/Publications/PublicationsPolicyAndGuidance/DH_063117</a></p><p>23</p><p>Less noted was a second concern: could we have foreseen this disaster? TGN1412 is a molecule that attaches to a receptor called CD28 on the white blood cells of the immune system. It was a new and experimental treatment, and it interfered with the immune system in ways that are poorly understood, and hard to model in animals (unlike, say, blood pressure, because immune systems are very variable between different species). But as the final report found, there was experience with a similar intervention: it had simply not been published. One researcher presented the inquiry with unpublished data on a study he had conducted in a single human subject a full ten years earlier, using an antibody that attached to the CD3, CD2 and CD28 receptors. The effects of this antibody had parallels with those of TGN1412, and the subject on whom it was tested had become unwell. But nobody could possibly have known that, because these results were never shared with the scientific community. They sat unpublished, unknown, when they could have helped save six men from a terrifying, destructive, avoidable ordeal.</p><p>24</p><p>That original researcher could not foresee the specific harm he contributed to, and it’s hard to blame him as an individual, because he operated in an academic culture where leaving data unpublished was regarded as completely normal. The same culture exists today. The final report on TGN1412 concluded that sharing the results of all first-in-man studies was essential: they should be published, every last one, as a matter of routine. But phase 1 trial results weren’t published then, and they’re still not published now. In 2009, for the first time, a study was published looking specifically at how many of these first-in-man trials get published, and how many remain hidden.9 They took all such trials approved by one ethics committee over a year. After four years, nine out of ten remained published; after eight years, four out of five were still unpublished.</p><p>429</p><p>9 Decullier E, Chan A-W, Chapuis F. Inadequate Dissemination of Phase I Trials: A Retrospective Cohort Study. PLoS Med. 2009 Feb 17;6(2):e1000034.</p><p>24</p><p>In medicine, as we shall see time and again, research is not abstract: it relates directly to life, death, suffering and pain. With every one of these unpublished studies we are potentially exposed, quite unnecessarily, to another TGN1412. Even a huge international news story, with horrific images of young men brandishing blackened feet and hands from hospital beds, wasn’t enough to get movement, because the issue of missing data is too complicated to fit in one sentence.</p><p>24</p><p>When we don’t share the results of basic research, such as a small first-in-man study, we expose people to unnecessary risks in the future. Was this an extreme case? Is the problem limited to early, experimental, new drugs, in small groups of trial participants? No.</p><p>25</p><p>In the 1980s, doctors began giving anti-arrhythmic drugs to all patients who’d had a heart attack. This practice made perfect sense on paper: we knew that anti-arrhythmic drugs helped prevent abnormal heart rhythms; we also knew that people who’ve had a heart attack are quite likely to have abnormal heart rhythms; we also knew that often these went unnoticed, undiagnosed and untreated. Giving anti-arrhythmic drugs to everyone who’d had a heart attack was a simple, sensible, preventive measure.</p><p>25</p><p>Unfortunately, it turned out that we were wrong. This prescribing practice, with the best of intentions, on the best of principles, actually killed people. And because heart attacks are very common, it killed them in very large numbers: well over 100,000 people died unnecessarily before it was realised that the fine balance between benefit and risk was completely different for patients without a proven abnormal heart rhythm.</p><p>25</p><p>Could anyone have predicted this? Sadly, yes, they could have. A trial in 1980 tested a new anti-arrhythmic drug, lorcainide, in a small number of men who’d had a heart attack – less than a hundred – to see if it was any use. Nine out of forty-eight men on lorcainide died, compared with one out of forty-seven on placebo. The drug was early in its development cycle, and not long after this study it was dropped for commercial reasons. Because it wasn’t on the market, nobody even thought to publish the trial. The researchers assumed it was an idiosyncrasy of their molecule, and gave it no further thought. If they had published, we would have been much more cautious about trying other anti-arrhythmic drugs on people with heart attacks, and the phenomenal death toll – over 100,000 people in their graves prematurely – might have been stopped sooner. More than a decade later, the researchers finally did publish their results, with a mea culpa, recognising the harm they had done by not sharing them earlier:</p><p>When we carried out our study in 1980, we thought that the increased death rate that occurred in the lorcainide group was an effect of chance. The development of lorcainide was abandoned for commercial reasons, and this study was therefore never published; it is now a good example of ‘publication bias’. The results described here might have provided an early warning of trouble ahead.10</p><p>430</p><p>10 Cowley AJ, Skene A, Stainer K, Hampton JR. The effect of lorcainide on arrhythmias and survival in patients with acute myocardial infarction: an example of publication bias. International journal of cardiology. 1993;40(2):161–6. Iain Chalmers was the first to raise TGN1412 and anti-arrhythmics as examples of the harm done when individual early trials are left unpublished. They are the best illustrations of this problem, but you should not imagine that they are unusual: the quantitative data shows that they are just two among many, many similar cases.</p><p>26</p><p>Because researchers are free to bury any result they please, patients are exposed to harm on a staggering scale throughout the whole of medicine, from research to practice. Doctors can have no idea about the true effects of the treatments they give. Does this drug really work best, or have I simply been deprived of half the data? Nobody can tell. Is this expensive drug worth the money, or have the data simply been massaged? No one can tell. Will this drug kill patients? Is there any evidence that it’s dangerous? No one can tell.</p><p>27</p><p>Missing data has been studied extensively in medicine. But before I lay out that evidence, we need to understand exactly why it matters, from a scientific perspective. And for that we need to understand systematic reviews and ‘meta-analysis’. Between them, these are two of the most powerful ideas in modern medicine. They are incredibly simple, but they were invented shockingly late.</p><p>27</p><p>When we want to find out if something works or not, we do a trial. This is a very simple process, and the first recorded attempt at some kind of trial was in the Bible (Daniel 1:12, if you’re interested). Firstly, you need an unanswered question: for example, ‘Does giving steroids to a woman delivering a premature baby increase the chances of that baby surviving?’ Then you find some relevant participants, in this case, mothers about to deliver a premature baby. You’ll need a reasonable number of them, let’s say two hundred for this trial. Then you divide them into two groups at random, give the mothers in one group the current best treatment (whatever that is in your town), while the mothers in the other group get current best treatment plus some steroids. Finally, when all two hundred women have gone through your trial, you count up how many babies survived in each group.</p><p>27</p><p>This is a real-world question, and lots of trials were done on this topic, starting from 1972 onwards: two trials showed that steroids saved lives, but five showed no significant benefit. Now, you will often hear that doctors disagree when the evidence is mixed, and this is exactly that kind of situation. A doctor with a strong pre-existing belief that steroids work – perhaps preoccupied with some theoretical molecular mechanism, by which the drug might do something useful in the body – could come along and say: ‘Look at these two positive trials! Of course we must give steroids!’ A doctor with a strong prior intuition that steroids were rubbish might point at the five negative trials and say: ‘Overall the evidence shows no benefit. Why take a risk?’</p><p>28</p><p>Up until very recently, this was basically how medicine progressed. People would write long, languorous review articles – essays surveying the literature – in which they would cite the trial data they’d come across in a completely unsystematic fashion, often reflecting their own prejudices and values. Then, in the 1980s, people began to do something called a ‘systematic review’. This is a clear, systematic survey of the literature, with the intention of getting all the trial data you can possibly find on one topic, without being biased towards any particular set of findings. In a systematic review, you describe exactly how you looked for data: which databases you searched, which search engines and indexes you used, even what words you searched for. You pre-specify the kinds of studies that can be included in your review, and then you present everything you’ve found, including the papers you rejected, with an explanation of why. By doing this, you ensure that your methods are fully transparent, replicable and open to criticism, providing the reader with a clear and complete picture of the evidence. It may sound like a simple idea, but systematic reviews are extremely rare outside clinical medicine, and are quietly one of the most important and transgressive ideas of the past forty years.</p><p>28</p><p>When you’ve got all the trial data in one place, you can conduct something called a meta-analysis, where you bring all the results together in one giant spreadsheet, pool all the data and get one single, summary figure, the most accurate summary of all the data on one clinical question. The output of this is called a ‘blobbogram’, and you can see one on the opposite page, in the logo of the Cochrane Collaboration, a global, non-profit academic organisation that has been producing gold-standard reviews of evidence on important questions in medicine since the 1980s.</p><p>29</p><p>This blobbogram shows the results of all the trials done on giving steroids to help premature babies survive. Each horizontal line is a trial: if that line is further to the left, then the trial showed steroids were beneficial and saved lives. The central, vertical line is the ‘line of no effect’: and if the horizontal line of the trial touches the line of no effect, then that trial showed no statistically significant benefit. Some trials are represented by longer horizontal lines: these were smaller trials, with fewer participants, which means they are prone to more error, so the estimate of the benefit has more uncertainty, and therefore the horizontal line is longer. Finally, the diamond at the bottom shows the ‘summary effect’: this is the overall benefit of the intervention, pooling together the results of all the individual trials. These are much narrower than the lines for individual trials, because the estimate is much more accurate: it is summarising the effect of the drug in many more patients. On this blobbogram you can see – because the diamond is a long way from the line of no effect – that giving steroids is hugely beneficial. In fact, it reduces the chances of a premature baby dying by almost half.</p><p>29</p><p>The amazing thing about this blobbogram is that it had to be invented, and this happened very late in medicine’s history. For many years we had all the information we needed to know that steroids saved lives, but nobody knew they were effective, because nobody did a systematic review until 1989. As a result, the treatment wasn’t given widely, and huge numbers of babies died unnecessarily; not because we didn’t have the information, but simply because we didn’t synthesise it together properly.</p><p>30</p><p>In case you think this is an isolated case, it’s worth examining exactly how broken medicine was until frighteningly recent times. The diagram on the opposite page contains two blobbo-grams, or ‘forest plots’, showing all the trials ever conducted to see whether giving streptokinase, a clot-busting drug, improves survival in patients who have had a heart attack.11</p><p>430</p><p>11 Antman EM, Lau J, Kupelnick B, Mosteller F, Chalmers TC. A comparison of results of meta-analyses of randomized control trials and recommendations of clinical experts. Treatments for myocardial infarction. JAMA. 1992 Jul 8;268(2):240–8.</p><p>30</p><p>Look first only at the forest plot on the following page. This is a conventional forest plot, from an academic journal, so it’s a little busier than the stylised one in the Cochrane logo. The principles, however, are exactly the same. Each horizontal line is a trial, and you can see that there is a hodgepodge of results, with some trials showing a benefit (they don’t touch the vertical line of no effect, headed ‘1’) and some showing no benefit (they do cross that line). At the bottom, however, you can see the summary effect – a dot on this old-fashioned blobbogram, rather than a diamond. And you can see very clearly that overall, streptokinase saves lives.</p><p>30</p><p>So what’s that on the right? It’s something called a cumulative meta-analysis. If you look at the list of studies on the left of the diagram, you can see that they are arranged in order of date. The cumulative meta-analysis on the right adds in each new trial’s results, as they arrived over history, to the previous trials’ results. This gives the best possible running estimate, each year, of how the evidence would have looked at that time, if anyone had bothered to do a meta-analysis on all the data available to them. From this cumulative blobbogram you can see that the horizontal lines, the ‘summary effects’, narrow over time as more and more data is collected, and the estimate of the overall benefit of this treatment becomes more accurate. You can also see that these horizontal lines stopped touching the vertical line of no effect a very long time ago – and crucially, they do so a long time before we started giving streptokinase to everyone with a heart attack.</p><p>31</p><p>In case you haven’t spotted it for yourself already – to be fair, the entire medical profession was slow to catch on – this chart has devastating implications. Heart attacks are an incredibly common cause of death. We had a treatment that worked, and we had all the information we needed to know that it worked, but once again we didn’t bring it together systematically to get that correct answer. Half of the people in those trials at the bottom of the blobbogram were randomly assigned to receive no streptokinase, I think unethically, because we had all the information we needed to know that streptokinase worked: they were deprived of effective treatments. But they weren’t alone, because so were most of the rest of the people in the world at the time.</p><p>31</p><p>These stories illustrate, I hope, why systematic reviews and meta-analyses are so important: we need to bring together all of the evidence on a question, not just cherry-pick the bits that we stumble upon, or intuitively like the look of. Mercifully the medical profession has come to recognise this over the past couple of decades, and systematic reviews with meta-analyses are now used almost universally, to ensure that we have the most accurate possible summary of all the trials that have been done on a particular medical question.</p><p>32</p><p>But these stories also demonstrate why missing trial results are so dangerous. If one researcher or doctor ‘cherry-picks’, when summarising the existing evidence, and looks only at the trials that support their hunch, then they can produce a misleading picture of the research. That is a problem for that one individual (and for anyone who is unwise or unlucky enough to be influenced by them). But if we are all missing the negative trials, the entire medical and academic community, around the world, then when we pool the evidence to get the best possible view of what works – as we must do – we are all completely misled. We get a misleading impression of the treatment’s effectiveness: we incorrectly exaggerate its benefits; or perhaps even find incorrectly that an intervention was beneficial, when in reality it did harm.</p><p>32</p><p>Now that you understand the importance of systematic reviews, you can see why missing data matters. But you can also appreciate that when I explain how much trial data is missing, I am giving you a clean overview of the literature, because I will be explaining that evidence using systematic reviews.</p><p>32</p><p>If you want to prove that trials have been left unpublished, you have an interesting problem: you need to prove the existence of studies you don’t have access to. To work around this, people have developed a simple approach: you identify a group of trials you know have been conducted and completed, then check to see if they have been published. Finding a list of completed trials is the tricky part of this job, and to achieve it people have used various strategies: trawling the lists of trials that have been approved by ethics committees (or ‘institutional review boards’ in the USA), for example; or chasing up the trials discussed by researchers at conferences.</p><p>33</p><p>In 2008 a group of researchers decided to check for publication of every trial that had ever been reported to the US Food and Drug Administration for all the antidepressants that came onto the market between 1987 and 2004. This was no small task. The FDA archives contain a reasonable amount of information on all the trials that were submitted to the regulator in order to get a licence for a new drug. But that’s not all the trials, by any means, because those conducted after the drug has come onto the market will not appear there; and the information that is provided by the FDA is hard to search, and often scanty. But it is an important subset of the trials, and more than enough for us to begin exploring how often trials go missing, and why. It’s also a representative slice of trials from all the major drug companies.</p><p>33</p><p>The researchers found seventy-four studies in total, representing 12,500 patients’ worth of data. Thirty-eight of these trials had positive results, and found that the new drug worked; thirty-six were negative. The results were therefore an even split between success and failure for the drugs, in reality. Then the researchers set about looking for these trials in the published academic literature, the material available to doctors and patients. This provided a very different picture. Thirty-seven of the positive trials – all but one – were published in full, often with much fanfare. But the trials with negative results had a very different fate: only three were published. Twenty-two were simply lost to history, never appearing anywhere other than in those dusty, disorganised, thin FDA files. The remaining eleven which had negative results in the FDA summaries did appear in the academic literature, but were written up as if the drug was a success. If you think this sounds absurd, I agree: we will see in Chapter 4, on ‘bad trials’, how a study’s results can be reworked and polished to distort and exaggerate its findings.</p><p>34</p><p>This was a remarkable piece of work, spread over twelve drugs from all the major manufacturers, with no stand-out bad guy. It very clearly exposed a broken system: in reality we have thirty-eight positive trials and thirty-seven negative ones; in the academic literature we have forty-eight positive trials and three negative ones. Take a moment to flip back and forth between those in your mind: ‘thirty-eight positive trials, thirty-seven negative’; or ‘forty-eight positive trials and only three negative’.</p><p>34</p><p>If we were talking about one single study, from one single group of researchers, who decided to delete half their results because they didn’t give the overall picture they wanted, then we would quite correctly call that act ‘research misconduct’. Yet somehow when exactly the same phenomenon occurs, but with whole studies going missing, by the hands of hundreds and thousands of individuals, spread around the world, in both the public and private sector, we accept it as a normal part of life.12 It passes by, under the watchful eyes of regulators and professional bodies who do nothing, as routine, despite the undeniable impact it has on patients.</p><p>430</p><p>12 Here is the classic early paper arguing this point: Chalmers Iain. Underreporting Research Is Scientific Misconduct. JAMA. 1990 Mar 9;263(10):1405–1408.</p><p>13 Sterling T. Publication decisions and their possible effects on inferences drawn from tests of significance – or vice versa. Am Stat Assoc J 1959;54:30–4.</p><p>34</p><p>Even more strange is this: we’ve known about the problem of negative studies going missing for almost as long as people have been doing serious science.</p><p>This was first formally documented by a psychologist called Theodore Sterling in 1959.13 He went through every paper published in the four big psychology journals of the time, and found that 286 out of 294 reported a statistically significant result. This, he explained, was plainly fishy: it couldn’t possibly be a fair representation of every study that had been conducted, because if we believed that, we’d have to believe that almost every theory ever tested by a psychologist in an experiment had turned out to be correct. If psychologists really were so great at predicting results, there’d hardly be any point in bothering to run experiments at all. In 1995, at the end of his career, the same researcher came back to the same question, half a lifetime later, and found that almost nothing had changed.14</p><p>430</p><p>14 Sterling TD, Rosenbaum WL, Weinkam JJ. Publication decisions revisited – the effect of the outcome of statistical tests on the decision to publish and vice-versa. Am Stat 1995;49:108–12.</p><p>35</p><p>Sterling was the first to put these ideas into a formal academic context, but the basic truth had been recognised for many centuries. Francis Bacon explained in 1620 that we often mislead ourselves by only remembering the times something worked, and forgetting those when it didn’t.15 Fowler in 1786 listed the cases he’d seen treated with arsenic, and pointed out that he could have glossed over the failures, as others might be tempted to do, but had included them.16 To do otherwise, he explained, would have been misleading.</p><p>430</p><p>15 Bacon F (1645). Franc Baconis de Verulamio/Summi Angliae Cancellarii/Novum organum scientiarum. [Francis Bacon of St. Albans Lord Chancellor of England. A ‘New Instrument’ for the sciences] Lugd. Bat: apud Adrianum Wiingaerde, et Franciscum Moiardum. Aphorism XLVI (p.45–46).</p><p>16 Fowler T (1786). Medical reports of the effects of arsenic in the cure of agues, remitting feveres and periodic headachs. London: J Johnson, pp 105–107.</p><p>36</p><p>Yet it was only three decades ago that people started to realise that missing trials posed a serious problem for medicine. In 1980 Elina Hemminki found that almost half the trials conducted in the mid-1970s in Finland and Sweden had been left unpublished.17 Then, in 1986, an American researcher called Robert Simes decided to investigate the trials on a new treatment for ovarian cancer. This was an important study, because it looked at a life-or-death question. Combination chemotherapy for this kind of cancer has very tough side effects, and knowing this, many researchers had hoped it might be better to give a single ‘alkylating agent’ drug first, before moving on to full chemotherapy. Simes looked at all the trials published on this question in the academic literature, read by doctors and academics. From this, giving a single drug first looked like a great idea: women with advanced ovarian cancer (which is not a good diagnosis to have) who were on the alkylating agent alone were significantly more likely to survive longer.</p><p>430</p><p>17 Hemminki E. Study of information submitted by drug companies to licensing authorities. Br Med J. 1980 Mar 22;280(6217):833–6.</p><p>37</p><p>Then Simes had a smart idea. He knew that sometimes trials can go unpublished, and he had heard that papers with less ‘exciting’ results are the most likely to go missing. To prove that this has happened, though, is a tricky business: you need to find a fair, representative sample of all the trials that have been conducted, and then compare their results with the smaller pool of trials that have been published, to see if there are any embarrassing differences. There was no easy way to get this information from the medicines regulator (we will discuss this problem in some detail later), so instead he went to the International Cancer Research Data Bank. This contained a register of interesting trials that were happening in the USA, including most of the ones funded by the government, and many others from around the world. It was by no means a complete list, but it did have one crucial feature: the trials were registered before their results came in, so any list compiled from this source would be, if not complete, at least a representative sample of all the research that had ever been done, and not biased by whether their results were positive or negative.</p><p>37</p><p>When Simes compared the results of the published trials against the pre-registered trials, the results were disturbing. Looking at the academic literature – the studies that researchers and journal editors chose to publish – alkylating agents alone looked like a great idea, reducing the rate of death from advanced ovarian cancer significantly. But when you looked only at the pre-registered trials – the unbiased, fair sample of all the trials ever conducted – the new treatment was no better than old-fashioned chemotherapy.</p><p>38</p><p>Simes immediately recognised – as I hope you will too – that the question of whether one form of cancer treatment is better than another was small fry compared to the depth charge he was about to set off in the medical literature. Everything we thought we knew about whether treatments worked or not was probably distorted, to an extent that might be hard to measure, but that would certainly have a major impact on patient care. We were seeing the positive results, and missing the negative ones. There was one clear thing we should do about this: start a registry of all clinical trials, demand that people register their study before they start, and insist that they publish the results at the end.</p><p>38</p><p>One research approach is to get all the trials that a medicines regulator has record of, from the very early ones done for the purposes of getting a licence for a new drug, and then check to see if they all appear in the academic literature. That’s the method we saw used in the paper mentioned above, where researchers sought out every paper on twelve antidepressants, and found that a 50/50 split of positive and negative results turned into forty-eight positive papers and just three negative ones. This method has been used extensively in several different areas of medicine:</p><p>39</p><p>Lee and colleagues, for example, looked for all of the 909 trials submitted alongside marketing applications for all ninety new drugs that came onto the market from 2001 to 2002: they found that 66 per cent of the trials with significant results were published, compared with only 36 per cent of the rest.18</p><p>430</p><p>18 Lee K, Bacchetti P, Sim I. Publication of clinical trials supporting successful new drug applications: a literature analysis. PLoS Med 2008;5(9):e191.</p><p>39</p><p>Melander, in 2003, looked for all forty-two trials on five antidepressants that were submitted to the Swedish drug regulator in the process of getting a marketing authorisation: all twenty-one studies with significant results were published; only 81 per cent of those finding no benefit were published.19</p><p>431</p><p>19 Melander H, Ahlqvist-Rastad J, Meijer G, Beermann B. Evidence b(i)ased medicine – selective reporting from studies sponsored by pharmaceutical industry: review of studies in new drug applications. BMJ 2003;326:1171–3.</p><p>39</p><p>Rising et al., in 2008, found more of those distorted write-ups that we’ll be dissecting later: they looked for all trials on two years’ worth of approved drugs. In the FDA’s summary of the results, once those could be found, there were 164 trials. Those with favourable outcomes were a full four times more likely to be published in academic papers than those with negative outcomes. On top of that, four of the trials with negative outcomes changed, once they appeared in the academic literature, to favour the drug.20</p><p>431</p><p>20 Rising K, Bacchetti P, Bero L. Reporting Bias in Drug Trials Submitted to the Food and Drug Administration: Review of Publication and Presentation. PLoS Med. 2008 Nov 25;5(11):e217.</p><p>39</p><p>If you prefer, you can look at conference presentations: a huge amount of research gets presented at conferences, but our current best estimate is that only about half of it ever appears in the academic literature.21 Studies presented only at conferences are almost impossible to find, or cite, and are especially hard to assess, because so little information is available on the specific methods used in the research (often as little as a paragraph). And as you will see shortly, not every trial is a fair test of a treatment. Some can be biased by design, so these details matter.</p><p>40</p><p>The most recent systematic review of studies looking at what happens to conference papers was done in 2010, and it found thirty separate studies looking at whether negative conference presentations – in fields as diverse as anaesthetics, cystic fibrosis, oncology, and A&E – disappear before becoming fully-fledged academic papers.22 Overwhelmingly, unflattering results are much more likely to go missing.</p><p>431</p><p>21 Scherer RW, Langenberg P, von Elm E. Full publication of results initially presented in abstracts. Cochrane Database Syst Rev 2007; 2: MR000005.</p><p>22 Song F, Parekh S, Hooper L, Loke YK, Ryder J, Sutton AJ, et al. Dissemination and publication of research findings: an updated review of related biases. Health Technol Assess. 2010 Feb;14(8):iii, ix–xi, 1–193.</p><p>40</p><p>If you’re very lucky, you can track down a list of trials whose existence was publicly recorded before they were started, perhaps on a register that was set up to explore that very question. From the pharmaceutical industry, up until very recently, you’d be very lucky to find such a list in the public domain. For publicly-funded research the story is a little different, and here we start to learn a new lesson: although the vast majority of trials are conducted by the industry, with the result that they set the tone for the community, this phenomenon is not limited to the commercial sector.</p><p>Note: even tho money makes a bigger difference, I still believe that they genuinely believe what they have been told in medical school and are just engaging in confirmation bias</p><p>40</p><p>By 1997 there were already four studies in a systematic review on this approach. They found that studies with significant results were two and a half times more likely to get published than those without.23</p><p>431</p><p>23 Dickersin K. How important is publication bias? A synthesis of available data. Aids Educ Prev 1997;9(1 SA):15–21.</p><p>40</p><p>A paper from 1998 looked at all trials from two groups of triallists sponsored by the US National Institutes of Health over the preceding ten years, and found, again, that studies with significant results were more likely to be published.24</p><p>431</p><p>24 Ioannidis J. Effect of the statistical significance of results on the time to completion and publication of randomized efficacy trials. JAMA 1998;279:281–6.</p><p>40</p><p>Another looked at drug trials notified to the Finnish National Agency, and found that 47 per cent of the positive results were published, but only 11 per cent of the negative ones.25</p><p>431</p><p>25 Bardy AH. Bias in reporting clinical trials. Brit J Clin Pharmaco 1998;46:147–50.</p><p>40</p><p>Another looked at all the trials that had passed through the pharmacy department of an eye hospital since 1963: 93 per cent of the significant results were published, but only 70 per cent of the negative ones.26</p><p>431</p><p>26 Dwan K, Altman DG, Arnaiz JA, Bloom J, Chan AW, Cronin E, et al. Systematic review of the empirical evidence of study publication bias and outcome reporting bias. PLoS ONE 2008;3(8):e3081.</p><p>40</p><p>The point being made in this blizzard of data is simple: this is not an under-researched area; the evidence has been with us for a long time, and it is neither contradictory nor ambiguous.</p><p>41</p><p>Two French studies in 2005 and 2006 took a new approach: they went to ethics committees, and got lists of all the studies they had approved, and then found out from the investigators whether the trials had produced positive or negative results, before finally tracking down the published academic papers.27 The first study found that significant results were twice as likely to be published; the second that they were four times as likely. In Britain, two researchers sent a questionnaire to all the lead investigators on 101 projects paid for by NHS R&D: it’s not industry research, but it’s worth noting anyway. This produced an unusual result: there was no statistically significant difference in the publication rates of positive and negative papers.28</p><p>431</p><p>27 Decullier E, Lhéritier V, Chapuis F. Fate of biomedical research protocols and publication bias in France: retrospective cohort study. BMJ 2005;331:19. Decullier E, Chapuis F. Impact of funding on biomedical research: a retrospective cohort study. BMC Public Health 2006;6:165.</p><p>28 Cronin E, Sheldon T. Factors influencing the publication of health research. Int J Technol Assess 2004;20:351–5.</p><p>431</p><p>29 Song F, Parekh S, Hooper L, Loke YK, Ryder J, Sutton AJ, et al. Dissemination and publication of research findings: an updated review of related biases. Health Technol Assess. 2010 Feb;14(8):iii, ix–xi, 1–193.</p><p>41</p><p>But it’s not enough simply to list studies. Systematically taking all the evidence that we have so far, what do we see overall?</p><p>It’s not ideal to lump every study of this type together in one giant spreadsheet, to produce a summary figure on publication bias, because they are all very different, in different fields, with different methods. This is a concern in many meta-analyses (though it shouldn’t be overstated: if there are lots of trials comparing one treatment against placebo, say, and they’re all using the same outcome measurement, then you might be fine just lumping them all in together).</p><p>But you can reasonably put some of these studies together in groups. The most current systematic review on publication bias, from 2010, from which the examples above are taken, draws together the evidence from various fields.29 Twelve comparable studies follow up conference presentations, and taken together they find that a study with a significant finding is 1.62 times more likely to be published. For the four studies taking lists of trials from before they started, overall, significant results were 2.4 times more likely to be published. Those are our best estimates of the scale of the problem. They are current, and they are damning.</p><p>42</p><p>All of this missing data is not simply an abstract academic matter: in the real world of medicine, published evidence is used to make treatment decisions. This problem goes to the core of everything that doctors do, so it’s worth considering in some detail what impact it has on medical practice. Firstly, as we saw in the case of reboxetine, doctors and patients are misled about the effects of the medicines they use, and can end up making decisions that cause avoidable suffering, or even death. We might also choose unnecessarily expensive treatments, having been misled into thinking they are more effective than cheaper older drugs. This wastes money, ultimately depriving patients of other treatments, since funding for health care is never infinite.</p><p>42</p><p>It’s also worth being clear that this data is withheld from everyone in medicine, from top to bottom. NICE, for example, is the National Institute for Health and Clinical Excellence, created by the British government to conduct careful, unbiased summaries of all the evidence on new treatments. It is unable either to identify or to access data that has been withheld by researchers or companies on a drug’s effectiveness: NICE has no more legal right to that data than you or I do, even though it is making decisions about effectiveness, and cost-effectiveness, on behalf of the NHS, for millions of people. In fact, as we shall see, the MHRA and EMA (the European Medicines Agency) – the regulators that decide which drugs can go on the market in the UK – often have access to this information, but do not share it with the public, with doctors, or with NICE. This is an extraordinary and perverse situation.</p><p>43</p><p>So, while doctors are kept in the dark, patients are exposed to inferior treatments, ineffective treatments, unnecessary treatments, and unnecessarily expensive treatments that are no better than cheap ones; governments pay for unnecessarily expensive treatments, and mop up the cost of harms created by inadequate or harmful treatment; and individual participants in trials, such as those in the TGN1412 study, are exposed to terrifying, life-threatening ordeals, resulting in lifelong scars, again quite unnecessarily.</p><p>43</p><p>At the same time, the whole of the research project in medicine is retarded, as vital negative results are held back from those who could use them. This affects everyone, but it is especially egregious in the world of ‘orphan diseases’, medical problems that affect only small numbers of patients, because these corners of medicine are already short of resources, and are neglected by the research departments of most drug companies, since the opportunities for revenue are thinner. People working on orphan diseases will often research existing drugs that have been tried and failed in other conditions, but that have theoretical potential for the orphan disease. If the data from earlier work on these drugs in other diseases is missing, then the job of researching them for the orphan disease is both harder and more dangerous: perhaps they have already been shown to have benefits or effects that would help accelerate research; perhaps they have already been shown to be actively harmful when used on other diseases, and there are important safety signals that would help protect future research participants from harm. Nobody can tell you.</p><p>44</p><p>In many respects, after all, publication bias is a very human process. If you’ve done a study and it didn’t have an exciting, positive result, then you might wrongly conclude that your experiment isn’t very interesting to other researchers. There’s also the issue of incentives: academics are often measured, rather unhelpfully, by crude metrics like the numbers of citations for their papers, and the number of ‘high-impact’ studies they get into glamorous well-read journals. If negative findings are harder to publish in bigger journals, and less likely to be cited by other academics, then the incentives to work at disseminating them are lower. With a positive finding, meanwhile, you get a sense of discovering something new. Everyone around you is excited, because your results are exceptional.</p><p>45</p><p>One clear illustration of this problem came in 2010. A mainstream American psychology researcher called Daryl Bem published a competent academic paper, in a well-respected journal, showing evidence of precognition, the ability to see into the future.* These studies were well-designed, and the findings were statistically significant, but many people weren’t very convinced, for the same reasons you aren’t: if humans really could see into the future, we’d probably know about it already; and extraordinary claims require extraordinary evidence, rather than one-off findings.</p><p>45</p><p>But in fact the study has been replicated, though Bem’s positive results have not been. At least two groups of academics have rerun several of Bem’s experiments, using the exact same methods, and both found no evidence of precognition. One group submitted their negative results to the Journal of Personality and Social Psychology – the very same journal that published Bem’s paper in 2010 – and that journal rejected their paper out of hand. The editor even came right out and said it: we never publish studies that replicate other work.</p><p>46</p><p>Here we see the same problem as in medicine: positive findings are more likely to be published than negative ones. Every now and then, a freak positive result is published showing, for example, that people can see into the future. Who knows how many psychologists have tried, over the years, to find evidence of psychic powers, running elaborate, time-consuming experiments, on dozens of subjects – maybe hundreds – and then found no evidence that such powers exist? Any scientist trying to publish such a ‘So what?’ finding would struggle to get a journal to take it seriously, at the best of times. Even with the clear target of Bem’s paper on precognition, which was widely covered in serious newspapers across Europe and the USA, the academic journal with a proven recent interest in the question of precognition simply refused to publish a paper with a negative result. Yet replicating these findings was key – Bem himself said so in his paper – so keeping track of the negative replications is vital too.</p><p>47</p><p>People working in real labs will tell you that sometimes an experiment can fail to produce a positive result many times before the outcome you’re hoping for appears. What does that mean? Sometimes the failures will be the result of legitimate technical problems; but sometimes they will be vitally important statistical context, perhaps even calling the main finding of the research into question. Many research findings, remember, are not absolute black-and-white outcomes, but fragile statistical correlations. Under our current system, most of this contextual information about failure is just brushed under the carpet, and this has huge ramifications for the cost of replicating research, in ways that are not immediately obvious.</p><p>47</p><p>For example, researchers failing to replicate an initial finding may not know if they’ve failed because the original result was an overstated fluke, or because they’ve made some kind of mistake in their methods. In fact, the cost of proving that a finding was wrong is vastly greater than the cost of making it in the first place, because you need to run the experiment many more times to prove the absence of a finding, simply because of the way that the statistics of detecting weak effects work; and you also need to be absolutely certain that you’ve excluded all technical problems, to avoid getting egg on your face if your replication turns out to have been inadequate. These barriers to refutation may partly explain why it’s so easy to get away with publishing findings that ultimately turn out to be wrong.30</p><p>432</p><p>30 This was first pointed out to me by Jamie Heywood from PatientsLikeMe, who spent huge resources trying and failing to replicate research findings in another area of medicine. The last time I saw him we talked about writing up his idea that the likelihood of a claim being true is proportional to the cost of making it, and inversely proportional to the cost of refuting it. We’ve not done so, and until then, a description of our conversation is the only reference for this neat idea.</p><p>48</p><p>Publication bias is not just a problem in the more abstract corners of psychology research. In 2012 a group of researchers reported in the journal Nature how they tried to replicate fifty-three early laboratory studies of promising targets for cancer treatments: forty-seven of the fifty-three could not be replicated.31 This study has serious implications for the development of new drugs in medicine, because such unreplicable findings are not simply an abstract academic issue: researchers build theories on the back of them, trust that they’re valid, and investigate the same idea using other methods. If they are simply being led down the garden path, chasing up fluke errors, then huge amounts of research money and effort are being wasted, and the discovery of new medical treatments is being seriously retarded.</p><p>432</p><p>31 Begley CG, Ellis LM. Drug development: Raise standards for preclinical cancer research. Nature. 2012 Mar 28;483(7391): 531–3.</p><p>48</p><p>The authors of the study were clear on both the cause of and the solution for this problem. Fluke findings, they explained, are often more likely to be submitted to journals – and more likely to be published – than boring, negative ones. We should give more incentives to academics for publishing negative results; but we should also give them more opportunity.</p><p>48</p><p>This means changing the behaviour of academic journals, and here we are faced with a problem. Although they are usually academics themselves, journal editors have their own interests and agendas, and have more in common with everyday journalists and newspaper editors than some of them might wish to admit, as the episode of the precognition experiment above illustrates very clearly. Whether journals like this are a sensible model for communicating research at all is a hotly debated subject in academia, but this is the current situation. Journals are the gatekeepers, they make decisions on what’s relevant and interesting for their audience, and they compete for readers.</p><p>❗️</p><p>49</p><p>This can lead them to behave in ways that don’t reflect the best interests of science, because an individual journal’s desire to provide colourful content might conflict with the collective need to provide a comprehensive picture of the evidence. In newspaper journalism, there is a well-known aphorism: ‘When a dog bites a man, that’s not news; but when a man bites a dog…’ These judgements on newsworthiness in mainstream media have even been demonstrated quantitatively. One study in 2003, for example, looked at the BBC’s health news coverage over several months, and calculated how many people had to die from a given cause for one story to appear. 8,571 people died from smoking for each story about smoking; but there were three stories for every death from new variant CJD, or ‘mad cow disease’.32 Another, in 1992, looked at print-media coverage of drug deaths, and found that you needed 265 deaths from paracetamol poisoning for one story about such a death to appear in a paper; but every death from MDMA received, on average, one piece of news coverage.33</p><p>432</p><p>32 Harrabin R et al (2003). Health In The News, The King’s Fund, London, UK.</p><p>432</p><p>33 Forsyth, Alasdair J. M. 2001. Distorted? a quantitative exploration of drug fatality reports in the popular press. International Journal of Drug Policy 12, no. 5–6 (November 1): 435–453.</p><p>49</p><p>If similar judgements are influencing the content of academic journals, then we have a problem. But can it really be the case that academic journals are the bottleneck, preventing doctors and academics from having access to unflattering trial results about the safety and effectiveness of the drugs they use? This argument is commonly deployed by industry, and researchers too are often keen to blame journals for rejecting negative findings en masse. Luckily, this has been the subject of some research; and overall, while journals aren’t blameless, it’s hard to claim that they are the main source of this serious public-health problem. This is especially so since there are whole academic journals dedicated to publishing clinical trials, with a commitment to publishing negative results written into their constitutions.</p><p>50</p><p>But to be kind, for the sake of completeness, and because industry and researchers are so keen to pass the blame on to academic journals, we can see if what they claim is true.</p><p>50</p><p>One survey simply asked the authors of unpublished work if they had ever submitted it for publication. One hundred and twenty-four unpublished results were identified, by following up on every study approved by a group of US ethics committees, and when the researchers contacted the teams behind the unpublished results, it turned out that only six papers had ever actually been submitted and rejected.34 Perhaps, you might say, this was a freak finding. Another approach is to follow up all the papers submitted to one journal, and see if those with negative results are rejected more often. Here again, the journals seem blameless: 745 manuscripts submitted to the Journal of the American Medical Association (JAMA) were followed up, and there was no difference in acceptance rate for significant and non-significant findings.35 The same thing has been tried with papers submitted to the BMJ, the Lancet, Annals of Internal Medicine and the Journal of Bone and Joint Surgery.36 Again and again, no effect was found. Might that be because the journals played fair when they knew they were being watched? Turning around an entire publishing operation for one brief performance would be tough, but it’s possible.</p><p>432</p><p>34 Dickersin K, Min YI, Meinert CL: Factors influencing publication of research results: follow-up of applications submitted to two institutional review boards. JAMA 1992, 267:374–378.</p><p>35 Olson CM, Rennie D, Cook D, Dickersin K, Flanagin A, Hogan JW, Zhu Q, Reiling J, Pace B: Publication bias in editorial decision making. JAMA 2002, 287:2825–2828.</p><p>36 Lee KP, Boyd EA, Holroyd-Leduc JM, Bacchetti P, Bero LA. Predictors of publication: characteristics of submitted manuscripts associated with acceptance at major biomedical journals. Med J Aust 2006;184:621–6. Lynch JR, Cunningham MRA, Warme WJ, Schaad DC, Wolf FM, Leopold SS. Commercially funded and United States-based research is more likely to be published; good-quality studies with negative outcomes are not. J Bone Joint Surg Am 2007;89:1010–8. Okike K, Kocher MS, Mehlman CT, Heckman JD, Bhandari M. Publication bias in orthopaedic research: an analysis of scientific factors associated with publication in the Journal of Bone and Joint Surgery. J Bone Joint Surg Am 2008;90:595–601.</p><p>50</p><p>These studies all involved observing what has happened in normal practice. One last option is to run an experiment, sending identical papers to various journals, but changing the direction of the results at random, to see if that makes any difference to the acceptance rates. This isn’t something you’d want to do very often, because it wastes a lot of people’s time; but since publication bias matters, it has been regarded as a justifiable intrusion on a few occasions.</p><p>51</p><p>In 1990 a researcher called Epstein created a series of fictitious papers, with identical methods and presentation, differing only in whether they reported positive or negative results. He sent them at random to 146 social-work journals: the positive papers were accepted 35 per cent of the time, and the negative ones 26 per cent of the time, a difference that wasn’t large enough to be statistically significant.37</p><p>432</p><p>37 Epstein WM. Confirmation response bias among social work journals. Sci Techol Hum Values 1990;15:9–38.</p><p>51</p><p>Other studies have tried something similar on a smaller scale, not submitting a paper to a journal, but rather, with the assistance of the journal, sending spoof academic papers to individual peer reviewers: these people do not make the final decision on publication, but they do give advice to editors, so a window into their behaviour would be useful. These studies have had more mixed results. In one from 1977, sham papers with identical methods but different results were sent to seventy-five reviewers. Some bias was found from reviewers against findings that disagreed with their own views.38</p><p>❗️</p><p>433</p><p>38 Mahoney MJ. Publication prejudices: an experimental study of confirmatory bias in the peer review system. Cognitive Ther Res 1977;1:161–75.</p><p>51</p><p>Another study, from 1994, looked at reviewers’ responses to a paper on TENS machines: these are fairly controversial devices sold for pain relief. Thirty-three reviewers with strong views one way or the other were identified, and again it was found that their judgements on the paper were broadly correlated with their pre-existing views, though the study was small.39 Another paper did the same thing with papers on quack treatments; it found that the direction of findings had no effect on reviewers from mainstream medical journals deciding whether to accept them.40</p><p>433</p><p>39 Ernst E, Resch KL. Reviewer bias – a blinded experimental study. J Lab Clin Med 1994;124:178–82.</p><p>40 Abbot NE, Ernst E. Publication bias: direction of outcome less important than scientific quality. Perfusion 1998;11:182–4.</p><p>52</p><p>One final randomised trial from 2010 tried on a grand scale to see if reviewers really do reject ideas based on their pre-existing beliefs (a good indicator of whether journals are biased by results, when they should be focused simply on whether a study is properly designed and conducted). Fabricated papers were sent to over two hundred reviewers, and they were all identical, except for the results they reported: half of the reviewers got results they would like, half got results they wouldn’t. Reviewers were more likely to recommend publication if they received the version of the manuscript with results they’d like (97 per cent vs 80 per cent), more likely to detect errors in a manuscript whose results they didn’t like, and rated the methods more highly in papers whose results they liked.41</p><p>433</p><p>41 Emerson GB, Warme WJ, Wolf FM, Heckman JD, Brand RA, Leopold SS. Testing for the Presence of Positive-Outcome Bias in Peer Review: A Randomized Controlled Trial. Arch Intern Med. 2010 Nov 22;170(21):1934–9.</p><p>52</p><p>Overall, though, even if there are clearly rough edges in some domains, these results don’t suggest that the journals are the main cause of the problem of the disappearance of negative trials. In the experiments isolating the peer reviewers, those individual referees were biased in some studies, but they don’t have the last word on publication, and in all the studies which look at what happens to negative papers submitted to journals in the real world, the evidence shows that they proceed into print without problems. Journals may not be entirely innocent, but it would be wrong to lay the blame at their door.</p><p>52</p><p>In the light of all this, the data on what researchers say about their own behaviour is very revealing. In various surveys they have said that they thought there was no point in submitting negative results, because they would just be rejected by journals: 20 per cent of medical researchers said so in 1998;42 61 per cent of psychology and education researchers said so in 1991;43 and so on.44 If asked why they’ve failed to send in research for publication, the most common reasons researchers give are negative results, a lack of interest, or a lack of time.</p><p>433</p><p>42 Weber EJ, Callaham ML, Wears RL, Barton C, Young G. Unpublished research from a medical specialty meeting: why investigators fail to publish. JAMA 1998;280:257–9.</p><p>43 Kupfersmid J, Fiala M. A survey of attitudes and behaviors of authors who publish in psychology and education journals. Am Psychol 1991;46:249–50.</p><p>44 Song F, Parekh S, Hooper L, Loke YK, Ryder J, Sutton AJ, et al. Dissemination and publication of research findings: an updated review of related biases. Health Technol Assess. 2010 Feb;14(8):iii, ix–xi, 1–193.</p><p>53</p><p>This is the more abstract end of academia – largely away from the immediate world of clinical trials – but it seems that academics are mistaken, at best, about the reasons why negative results go missing. Journals may pose some barriers to publishing negative results, but they are hardly absolute, and much of the problem lies in academics’ motivations and perceptions.</p><p>53</p><p>More than that, in recent years, the era of open-access academic journals has got going in earnest: there are now several, such as Trials, which are free to access, and have a core editorial policy that they will accept any trial report, regardless of result, and will actively solicit negative findings. With offers like this on the table, it is very hard to believe that anyone would really struggle to publish a trial with a negative result if they wanted to. And yet, despite this, negative results continue to go missing, with vast multinational companies simply withholding results on their drugs, even though academics and doctors are desperate to see them.</p><p>53</p><p>You might reasonably wonder whether there are people who are supposed to prevent this kind of data from being withheld. The universities where research takes place, for example; or the regulators; or the ‘ethics committees’, which are charged with protecting patients who participate in research. Unfortunately, our story is about to take a turn to the dark side. We will see that many of the very people and organisations we would have expected to protect patients from the harm inflicted by missing data have, instead, shirked their responsibilities; and worse than that, we will see that many of them have actively conspired in helping companies to withhold data from patients. We are about to hit some big problems, some bad people, and some simple solutions.</p><p>54</p><p>By now, you will, I hope, share my view that withholding results from clinical trials is unethical, for the simple reason that hidden data exposes patients to unnecessary and avoidable harm. But the ethical transgressions here go beyond the simple harm inflicted on future patients.</p><p>Patients and the public participate in clinical trials at some considerable cost to themselves: they expose themselves to hassle and intrusion, because clinical trials almost always require that you have more check-ups on your progress, more blood tests, and more examinations; but participants may also expose themselves to more risk, or the chance of receiving an inferior treatment. People do this out of altruism, on the implicit understanding that the results from their experience will contribute to improving our knowledge of what works and what doesn’t, and so will help other patients in the future. In fact, this understanding isn’t just implicit: in many trials it’s explicit, because patients are specifically told when they sign up to participate that the data will be used to inform future decisions. If this isn’t true, and the data can be withheld at the whim of a researcher or a company, then the patients have been actively lied to. That is very bad news.</p><p>55</p><p>So what are the formal arrangements between patients, researchers and sponsors? In any sensible world, we’d expect universal contracts, making it clear that all researchers are obliged to publish their results, and that industry sponsors – which have a huge interest in positive results – must have no control over the data. But despite everything we know about industry-funded research being systematically biased, this does not happen. In fact, quite the opposite is true: it is entirely normal for researchers and academics conducting industry-funded trials to sign contracts subjecting them to gagging clauses which forbid them to publish, discuss or analyse data from the trials they have conducted, without the permission of the funder. This is such a secretive and shameful situation that even trying to document it in public can be a fraught business, as we shall now see.</p><p>55</p><p>In 2006 a paper was published in JAMA describing how common it was for researchers doing industry-funded trials to have these kinds of constraints placed on their right to publish the results.45 The study was conducted by the Nordic Cochrane Centre, and it looked at all the trials given approval to go ahead in Copenhagen and Frederiksberg. (If you’re wondering why these two cities were chosen, it was simply a matter of practicality, and the bizarre secrecy that shrouds this world: the researchers applied elsewhere without success, and were specifically refused access to data in the UK.46) These trials were overwhelmingly sponsored by the pharmaceutical industry (98 per cent), and the rules governing the management of the results tell a story which walks the now-familiar line between frightening and absurd.</p><p>433</p><p>45 Gøtzsche PC, Hróbjartsson A, Johansen HK, Haahr MT, Altman DG, Chan A-W: Constraints on publication rights in industry-initiated clinical trials. JAMA 2006, 295:1645–1646.</p><p>46 Gornall, J. ‘Industry attack on academics.’ BMJ 338, no. mar09 1 (March 9, 2009): b736–b736.</p><p>56</p><p>For sixteen of the forty-four trials the sponsoring company got to see the data as it accumulated, and in a further sixteen they had the right to stop the trial at any time, for any reason. This means that a company can see if a trial is going against it, and can interfere as it progresses. As we will see later (early stopping, breaking protocols, pp.184, 200), this distorts a trial’s results with unnecessary and hidden biases. For example, if you stop a trial early because you have been peeking at the preliminary results, then you can either exaggerate a modest benefit, or bury a worsening negative result. Crucially, the fact that the sponsoring company had this opportunity to introduce bias wasn’t mentioned in any of the published academic papers reporting the results of these trials, so nobody reading the literature could possibly know that these studies were subject – by design – to such an important flaw.</p><p>56</p><p>Even if the study was allowed to finish, the data could still be suppressed. There were constraints on publication rights in forty of the forty-four trials, and in half of them the contracts specifically stated that the sponsor either owned the data outright (what about the patients, you might say?), or needed to approve the final publication, or both. None of these restrictions was mentioned in any of the published papers, and in fact, none of the protocols or papers said that the sponsor had full access to all the data from the trial, or the final say on whether to publish.</p><p>56</p><p>It’s worth taking a moment to think about what this means. The results of all these trials were subject to a bias that will significantly distort the academic literature, because trials that show early signs of producing a negative result (or trials that do produce a negative result) can be deleted from the academic record; but nobody reading these trials could possibly have known that this opportunity for censorship existed.</p><p>57</p><p>The paper I’ve just described was published in JAMA, one of the biggest medical journals in the world. Shortly afterwards, a shocking tale of industry interference appeared in the BMJ.47 Lif, the Danish pharmaceutical industry association, responded to the paper by announcing in the Journal of the Danish Medical Association that it was ‘both shaken and enraged about the criticism, that could not be recognised’. It demanded an investigation of the scientists, though it failed to say by whom, or of what. Then Lif wrote to the Danish Committee on Scientific Dishonesty, accusing the Cochrane researchers of scientific misconduct. We can’t see the letter, but the Cochrane researchers say the allegations were extremely serious – they were accused of deliberately distorting the data – but vague, and without documents or evidence to back them up.</p><p>433</p><p>47 Ibid.</p><p>57</p><p>Nonetheless, the investigation went on for a year, because in academia people like to do things properly, and assume that all complaints are made in good faith. Peter Gøtzsche, the director of the Cochrane centre, told the BMJ that only Lif’s third letter, ten months into this process, made specific allegations that could be investigated by the committee. Two months later the charges were dismissed. The Cochrane researchers had done nothing wrong. But before they were cleared, Lif copied the letters alleging scientific dishonesty to the hospital where four of them worked, and to the management organisation running that hospital, and sent similar letters to the Danish Medical Association, the Ministry of Health, the Ministry of Science, and so on. Gøtzsche and his colleagues said that they felt ‘intimidated and harassed’ by Lif’s behaviour. Lif continued to insist that the researchers were guilty of misconduct even after the investigation was completed. So, researching in this area is not easy: it’s hard to get funding, and the industry will make your work feel like chewing on a mouthful of wasps.</p><p>58</p><p>Even though the problem has been widely recognised, attempts to fix it have failed.48 The International Committee of Medical Journal Editors, for example, stood up in 2001, insisting that the lead author of any study it published must sign a document stating that the researchers had full access to the data, and full control over the decision to publish. Researchers at Duke University, North Carolina, then surveyed the contracts between medical schools and industry sponsors, and found that this edict was flouted as a matter of routine. They recommended boilerplate contracts for the relationship between industry and academia. Was this imposed? No. Sponsors continue to control the data.</p><p>433</p><p>48 Steinbrook R. Gag clauses in clinical-trial agreements. N. Engl. J. Med. 2005 May 26;352(21):2160–2.</p><p>59</p><p>Half a decade later, a major study in the New England Journal of Medicine investigated whether anything had changed.49 Administrators at all 122 accredited medical schools in the US were asked about their contracts (to be clear, this wasn’t a study of what they did; rather it was a study of what they were willing to say in public). The majority said contract negotiations over the right to publish data were ‘difficult’. A worrying 62 per cent said it was OK for the clinical trial agreement between academics and industry sponsor to be confidential. This is a serious problem, as it means that anyone reading a study cannot know how much interference was available to the sponsor, which is important context for the person reading and interpreting the research.</p><p>433</p><p>49 Mello MM, Clarridge BR, Studdert DM. Academic medical centers’ standards for clinical-trial agreements with industry. N. Engl. J. Med. 2005;352(21):2202.</p><p>59</p><p>Half of the centres allowed the sponsor to draft the research paper, which is another interesting hidden problem in medicine, as biases and emphases can be quietly introduced (as we shall see in more detail in Chapter 6). Half said it was OK for contracts to forbid researchers sharing data after the research was completed and published, once again hindering research. A quarter said it was acceptable for the sponsor to insert its own statistical analyses into the manuscript. Asked about disputes, 17 per cent of administrators had seen an argument about who had control of data in the preceding year.</p><p>60</p><p>Sometimes, disputes over access to such data can cause serious problems in academic departments, when there is a divergence of views on what is ethical. Aubrey Blumsohn was a senior lecturer at Sheffield University, working on a project funded by Procter & Gamble to research an osteoporosis drug called risedronate.50 The aim was to analyse blood and urine samples from an earlier trial, led by Blumsohn’s head of department, Professor Richard Eastell. After signing the contracts, P&G sent over some ‘abstracts’, brief summaries of the findings, with Blumsohn’s name as first author, and some summary results tables. That’s great, said Blumsohn, but I’m the researcher here: I’d like to see the actual raw data and analyse it myself. The company declined, saying that this was not their policy. Blumsohn stood his ground, and the papers were left unpublished. Then, however, Blumsohn saw that Eastell had published another paper with P&G, stating that all the researchers had ‘had full access to the data and analyses’. He complained, knowing this was not true. Blumsohn was suspended by Sheffield University, which offered him a gagging clause and £145,000, and he was eventually forced out of his job. Eastell, meanwhile, was censured by the General Medical Council, but only after a staggering delay of several years, and he remains in post.</p><p>434</p><p>50 This is one of many stories for which I recommend delving into the horrible details, if you’re interested. A good place to start here is Prof David Colquhoun’s blog on the topic, with many links
<a href="http://www.dcscience.net/?p=193" rel=noopener>http://www.dcscience.net/?p=193</a> and this BMJ piece written by a lawyer, to keep the lawyers reading this book happy: Dyer C. Aubrey Blumsohn: Academic who took on industry. BMJ. 2009 Dec 15;339(dec15 1):b5293–b5293.</p><p>60</p><p>So contracts that permit companies and researchers to withhold or control data are common, and they’re bad news. But that’s not just because they lead to doctors and patients being misled about what works. They also break another vitally important contract: the agreement between researchers and the patients who participate in their trials.</p><p>61</p><p>People participate in trials believing that the results of that research will help to improve the treatment of patients like them in the future. This isn’t just speculation: one of the few studies to ask patients why they have participated in a trial found that 90 per cent believed they were making a ‘major’ or ‘moderate’ contribution to society, and 84 per cent felt proud that they were making this contribution.51 Patients are not stupid or naïve to believe this, because it is what they are told on the consent forms they sign before participating in trials. But they are mistaken, because the results of trials are frequently left unpublished, and withheld from doctors and patients. These signed consent forms therefore mislead people on two vitally important points. Firstly, they fail to tell the truth: that the person conducting the trial, or the person paying for it, may decide not to publish the results, depending on how they look at the end of the study. And worse than that, they also explicitly state a falsehood: researchers tell patients that they are participating in order to create knowledge that will be used to improve treatment in future, even though the researchers know that in many cases, those results will never be published.</p><p>434</p><p>51 Wendler D, Krohmal B, Emanuel EJ, Grady C, for the ESPRIT Group. Why Patients Continue to Participate in Clinical Research. Arch Intern Med. 2008 Jun 23;168(12):1294–9.</p><p>62</p><p>There is only one conclusion that we can draw from this: consent forms routinely lie to patients participating in trials. This is an extraordinary state of affairs, made all the more extraordinary by the huge amounts of red tape that everyone involved in a trial must negotiate, closely monitoring endless arcane pieces of paperwork, and ensuring that patients are fully informed on the minutiae of their treatment. Despite all this regulatory theatre, which hinders good research on routine practice (as we shall see – p.230), we allow these forms to tell patients outright lies about the control of data, and we fail to police one of the most important ethical problems in the whole of medicine. The deceit of these consent forms is, to me, a good illustration of how broken and outdated the regulatory frameworks of medicine have become. But it also, finally, poses a serious problem for the future of research.</p><p>62</p><p>We desperately need patients to continue to believe that they are contributing to society, because trial recruitment is in crisis, and it is increasingly hard to persuade patients to participate at all. In one recent study, a third of all trials failed to reach their original recruitment target, and more than half had to be awarded an extension.52 If word gets out that trials are often more promotional than genuinely scientific, recruitment will become even more difficult. The answer is not to hide this problem, but rather to fix it.</p><p>434</p><p>52 McDonald AM, Knight RC, Campbell MK, Entwistle VA, Grant AM, Cook JA, et al. What influences recruitment to randomised controlled trials? A review of trials funded by two UK funding agencies. Trials. 2006;7:9.</p><p>62</p><p>So universities and ethics committees may have failed us, but there is one group of people we might expect to step up, to try to show some leadership on missing trial data. These are the medical and academic professional bodies, the Royal Colleges of General Practice, Surgery and Physicians, the General Medical Council, the British Medical Association, the pharmacists’ organisations, the bodies representing each sub-specialty of academia, the respiratory physiologists, the pharmacologists, the Academy of Medical Sciences, and so on.</p><p>63</p><p>These organisations have the opportunity to set the tone of academic and clinical medicine, in their codes of conduct, their aspirations, and in some cases their rules, since some have the ability to impose sanctions, and all have the ability to exclude those who fail to meet basic ethical standards. We have established, I hope, beyond any doubt, that non-publication of trials in humans is research misconduct, that it misleads doctors and harms patients around the world. Have these organisations used their powers, stood up and announced, prominently and fiercely, that this must stop, and that they will take action?</p><p>63</p><p>One has: the Faculty of Pharmaceutical Medicine, a small organisation with 1,400 members. And none of the others have bothered.</p><p>Not one.</p><p>65</p><p>you might reasonably imagine that governments, regulators and medical journals must all have tried to address it.</p><p>65</p><p>They have tried, and failed. Worse than simply failing, they have repeatedly provided what we might regard as ‘fake fixes’: we have seen small changes in regulations and practices, announced with great fanfare, but then either ignored or bypassed. This has given false reassurance to doctors, academics and the public that the problem has been fixed. What follows is the story of these fake fixes.</p><p>66</p><p>The earliest and simplest solution proposed was to open registers of trials: if people are compelled to publish their protocol, in full, before they start work, then we at least have the opportunity to go back and check to see if they’ve published the trials that they’ve conducted. This is very useful, for a number of reasons. A trial protocol describes in great technical detail everything that researchers will do in a trial: how many patients they’ll recruit, where they’ll come from, how they’ll be divided up, what treatment each group will get, and what outcome will be measured to establish if the treatment was successful. Because of this, it can be used to check whether a trial was published, but also whether its methods were distorted along the way, in a manner that would allow the results to be exaggerated (as described in Chapter 4).</p><p>66</p><p>The first major paper to call for a registry of clinical trial protocols was published in 1986,53 and it was followed by a flood. In 1990 Iain Chalmers (we can call him Sir Iain Chalmers if you like*) published a classic paper called ‘Underreporting Research is Scientific Misconduct’,55 and he has traced the chequered history of trials registers in the UK.56 In 1992, as the Cochrane Collaboration began to gather influence, representatives of the Association of the British Pharmaceutical Industry (ABPI) asked to meet Chalmers.57 After explaining the work of Cochrane, and the vital importance of summarising all the trial results on a particular drug, he explained very clearly to them how biased under-reporting of results harms patients.</p><p>434</p><p>53 Simes RJ. Publication bias: the case for an international registry of clinical trials. Journal of Clinical Oncology. 1986 Oct 1;4(10):1529–1541.</p><p>54 Clarke M, Clarke L, Clarke T. Yes Sir, no Sir, not much difference Sir. JRSM. 2007 Dec 1;100(12):571–572.</p><p>55 Chalmers Iain. Underreporting Research Is Scientific Misconduct. JAMA: The Journal of the American Medical Association. 1990 Mar 9;263(10):1405–1408.</p><p>56 Chalmers I. From optimism to disillusion about commitment to transparency in the medico-industrial complex. JRSM. 2006 Jul 1;99(7):337–341.</p><p>57 Their delegation was led by Frank Wells: his textbook on fraud is fantastic. I tell you this because you should understand that these are not all bad people with inherently secretive natures.</p><p>67</p><p>The industry’s representatives were moved, and soon they took action. Mike Wallace, the chief executive of Schering and a member of that ABPI delegation, agreed with Chalmers that withholding data was ethically and scientifically indefensible, and said that he planned to do something concrete to prevent it, if only to protect the industry from having the issue forced upon it in less welcome terms. Wallace stepped out of line from his colleagues, and committed to registering every trial conducted by his company with Cochrane. This was not a popular move, and he was reprimanded by colleagues, in particular those from other companies.</p><p>67</p><p>But soon GlaxoWellcome followed suit, and in 1998 its chief executive, Richard Sykes, wrote an editorial in the BMJ called ‘Being a modern pharmaceutical company involves making information available on clinical trial programmes’.58 ‘Programmes’ was the crucial word, because as we’ve seen, and as we shall see in greater detail later, you can only make sense of individual findings if you assess them in the context of all the work that has been done on a drug.</p><p>434</p><p>58 Sykes R. Being a modern pharmaceutical company. BMJ. 1998 Oct 31;317(7167):1172–80.</p><p>67</p><p>GlaxoWellcome set up a clinical trials registry, and Elizabeth Wager, the head of the company’s medical writers group, pulled together a group from across the industry to develop ethical guidelines for presenting research. The ABPI, seeing individual companies take the lead, saw the writing on the wall: it decided to commend GlaxoWellcome’s policy to the whole industry, and launched this initiative at a press conference where Chalmers – a strong critic – sat on the same side of the table as the industry. AstraZeneca, Aventis, MSD, Novartis, Roche, Schering Healthcare and Wyeth began registering some of their trials – only the ones involving UK patients, and retrospectively – but there was movement at last.</p><p>68</p><p>At the same time, there was movement in America. The 1997 FDA Modernization Act created clinicaltrials.gov, a register run by the US government National Institute of Health. This legislation required that trials should be registered, but only if they related to an application to put a new drug on the market, and even then, only if it was for a serious or life-threatening disease. The register opened in 1998, and the website clinicaltrials.gov went online in 2000. The entry criteria were widened in 2004.</p><p>68</p><p>But soon it all began to fall apart. GlaxoWellcome merged with SmithKline Beecham to become GlaxoSmithKline (GSK), and initially the new logo appeared on the old trials register. Iain Chalmers wrote to Jean-Paul Garnier, the chief executive of the new company, to thank him for maintaining this valuable transparency: but no reply ever came. The registry website was closed, and the contents were lost (though GSK was later forced to open a new register, as part of a settlement with the US government over the harm caused by its withholding of data on new drug trials just a couple of years later). Elizabeth Wager, the author of GSK’s Good Publication Practice guidelines for drug companies, was out of a job, as her writing department in the company was closed. Her guidelines were ignored.</p><p>68</p><p>From the moment that these registries were first suggested, and then opened, it was implicitly assumed that the shame of producing this public record, and then not publishing your study, would be enough to ensure that people would do the right thing. But the first problem for the US register, which could have been used universally, was that people simply chose not to use it. The regulations required only a very narrow range of trials to be posted, and nobody else was in a hurry to post their trials if they didn’t have to.</p><p>69</p><p>In 2004 the International Committee of Medical Journal Editors (ICMJE) – a collection of editors from the most influential journals in the world – published a policy statement, announcing that none of them would publish any clinical trials after 2005, unless they had been properly registered before they began.59 They did this, essentially, to force the hand of the industry and researchers: if a trial has a positive result, then people desperately want to publish it in the most prestigious journal they can find. Although they had no legal force, the journal editors did have the thing that companies and researchers wanted most: the chance of a major journal publication. By insisting on pre-registration, they were doing what they could to force researchers and industry sponsors to register all trials. Everyone rejoiced: the problem had been fixed.</p><p>434</p><p>59 De Angelis C, Drazen JM, Frizelle FA, Haug C, Hoey J, Horton R, et al. Clinical trial registration: a statement from the International Committee of Medical Journal Editors. The Lancet. 2004 Sep 11;364(9438):911–2.</p><p>69</p><p>If you think it seems odd – and perhaps unrealistic – that fixing this crucial flaw in the information architecture of a $600 billion industry should be left to an informal gathering of a few academic editors, with no legislative power, then you’d be right. Although everybody began to talk as if publication bias was a thing of the past, in reality it was continuing just as before, because the journal editors simply ignored their own threats and promises. Later we will see the phenomenal financial inducements on offer to editors for publishing positive industry papers, which can extend to millions of dollars in reprint and advertising revenue. But first we should look at what they actually did after their solemn promise in 2005.</p><p>70</p><p>In 2008 a group of researchers went through every single trial published in the top ten medical journals, every one of which was a member of the ICMJE, after the deadline for pre-registration. Out of 323 trials published during 2008 in these high-impact academic journals, only half were adequately registered (before the trial, with the main outcome measure properly specified), and trial registration was entirely lacking for over a quarter.60 The ICMJE editors had simply failed to keep their word.</p><p>434</p><p>60 Mathieu S, Boutron I, Moher D, Altman DG, Ravaud P. Comparison of Registered and Published Primary Outcomes in Randomized Controlled Trials. JAMA. 2009 Sep 2;302(9):977–84.</p><p>70</p><p>Meanwhile, in Europe, there were some very bizarre developments. With enormous fanfare, the European Medicines Agency created a registry of trials called EudraCT. EU legislation requires all trials to be posted here if they involve any patients in Europe, and many companies will tell you that they’ve met their responsibilities for transparency by doing so. But the contents of this EU register have been kept entirely secret. I can tell you that it contains around 30,000 trials, since that figure is in the public domain, but that is literally all I know, and all anyone can know. Despite EU legislation requiring that the public should be given access to the contents of this register, it remains closed. This creates an almost laughable paradox: the EU clinical trials register is a transparency tool, held entirely in secret. Since March 2011, after heavy media criticism (from me at any rate), a subset of trials has slowly been made public through a website called EudraPharm. As of summer 2012, although the agency now claims that its register is accessible to all, at least 10,000 trials are still missing, and the search engine doesn’t work properly.61 It’s absolutely one of the strangest things I’ve ever seen, and nobody other than the EU even regards this peculiar exercise as a trials register: I certainly don’t, I doubt you do, and both the ICMJE and the World Health Organization have explicitly stated that EudraCT is not a meaningful register.</p><p>435</p><p>61 Wieseler B, McGauran N, Kaiser T. Still waiting for functional EU Clinical Trials Register. BMJ. 2011 Jun 20;342(jun20 2):d3834–d3834.</p><p>71</p><p>But new work was being done in the US, and it seemed sensible. In 2007 the FDA Amendment Act was passed. This is much tighter: it requires registration of all trials of any drug or device, at any stage of development other than ‘first-in-man’ tests, if they have any site in the US, or involve any kind of application to bring a new drug onto the market. It also imposes a startling new requirement: all results of all trials must be posted to clinicaltrials.gov, in abbreviated summary tables, within one year of completion, for any trial on any marketed drug that completes after 2007.</p><p>Once again, to great fanfare, everyone believed that the problem had been fixed. But it hasn’t been, for two very important reasons.</p><p>71</p><p>Firstly, unfortunately, despite the undoubted goodwill, requiring the publication of all trials starting from ‘now’ does absolutely nothing for medicine today. There is no imaginable clinic, anywhere in the world, at which medicine is practised only on the basis of trials that completed within the past three years, using only drugs that came to market since 2008. In fact, quite the opposite is true: the vast majority of drugs currently in use came to market over the past ten, twenty or thirty years, and one of the great challenges for the pharmaceutical industry today is to create drugs that are anything like as innovative as those that were introduced in what has come to be known as the ‘golden era’ of pharmaceutical research, when all the most widely used drugs, for all the most common diseases, were developed. Perhaps they were the ‘low-lying fruit’, plucked from the research tree, but in any case, these are the tablets we use.</p><p>71</p><p>And crucially, it is for these drugs – the ones we actually use – that we need the evidence: from trials completed in 2005 or 1995. These are the drugs that we are prescribing completely blind, misled by a biased sample of trials, selectively published, with the unflattering data buried in secure underground data archives somewhere in the hills (I am told) of Cheshire.</p><p>72</p><p>But there is a second, more disturbing reason why these regulations should be taken with a pinch of salt: they have been widely ignored. A study published in January 2012 looked at the first slice of trials subject to mandatory reporting, and found that only one in five had met its obligation to post results.62</p><p>435</p><p>62 Prayle AP, Hurley MN, Smyth AR. Compliance with mandatory reporting of clinical trial results on ClinicalTrials.gov: cross sectional study. BMJ. 2012;344:d7373.</p><p>72</p><p>Perhaps this is not surprising: the fine for non-compliance is $10,000 a day, which sounds spectacular, until you realise that it’s only $3.5 million a year, which is chickenfeed for a drug bringing in $4 billion a year. And what’s more, no such fine has ever been levied, throughout the entire history of the legislation.</p><p>72</p><p>So that, in total, is why I regard the ICMJE, the FDA and the EU’s claims to have addressed this problem as ‘fake fixes’. In fact, they have done worse than fail: they have given false reassurance that the problem has been fixed, false reassurance that it has gone away, and they have led us to take our eyes off the ball. For half a decade now, people in medicine and academia have talked about publication bias as if it was yesterday’s problem, discovered in the 1990s and early 2000s, and swiftly fixed.</p><p>But the problem of missing data has not gone away, and soon we will see exactly how shameless some companies and regulators can be, in the very present day.</p><p>73</p><p>While the published academic record is hopelessly distorted, you might hope that there is one final route which patients and doctors could use to get access to the results of clinical trials: the regulators, which receive large amounts of data from drug companies during the approval process, must surely have obligations to protect patients’ safety? But this, sadly, is just one more example of how we are failed by the very bodies that are supposed to be protecting us.</p><p>73</p><p>In this section, we will see three key failures. Firstly, the regulators may not have the information in the first place. Secondly, the way in which they ‘share’ summary trial information with doctors and patients is broken and shabby. And finally, if you try to get all of the information that a drug company has provided – the long-form documents, where the bodies are often buried – then regulators present bizarre barriers, blocking and obfuscating for several years at a time, even on drugs that turn out to be ineffective and harmful. Nothing of what I am about to tell you is in any sense reassuring.</p><p>74</p><p>Paroxetine is a commonly used antidepressant, from the class of drugs known as ‘selective serotonin reuptake inhibitors’, or SSRIs. You will hear more about this class of drugs later in this book, but here we will use paroxetine to show how companies have exploited our longstanding permissiveness about missing trials, and found loopholes in our inadequate regulations on trial disclosure. We will see that GSK withheld data about whether paroxetine works as an antidepressant, and even withheld data about its harmful side effects, but most importantly, we will see that what it did was all entirely legal.</p><p>74</p><p>To understand why, we first need to go through a quirk of the licensing process. Drugs do not simply come onto the market for use in all medical conditions: for any specific use of any drug, in any specific disease, you need a separate marketing authorisation. So, a drug might be licensed to treat ovarian cancer, for example, but not breast cancer. That doesn’t mean the drug doesn’t work in breast cancer. There might well be some evidence that it’s great for treating that disease too, but maybe the company hasn’t gone to the trouble and expense of getting a formal marketing authorisation for that specific use. Doctors can still go ahead and prescribe it for breast cancer, if they want, because the drug is available for prescription, and there are boxes of it sitting in pharmacies waiting to go out (even though, strictly speaking, it’s only got marketing approval for use in ovarian cancer). In this situation the doctor will be prescribing the drug legally, but ‘off-label’.</p><p>75</p><p>This is fairly common, as getting a marketing authorisation for a specific use can be time-consuming and expensive. If doctors know that there’s a drug which has been shown in good-quality trials to help treat a disease, it would be perverse and unhelpful of them not to prescribe it, just because the company hasn’t applied for a formal licence to market it for that specific use.</p><p>75</p><p>the use of a drug in children is treated as a separate marketing authorisation from its use in adults.</p><p>75</p><p>This makes sense in many cases, because children can respond to drugs in very different ways to adults, so the risks and benefits might be very different, and research needs to be done in children separately. But this licensing quirk also brings some disadvantages. Getting a licence for a specific use is an arduous business, requiring lots of paperwork, and some specific studies. Often this will be so expensive that companies will not bother to get a licence specifically to market a drug for use in children, because that market is usually much smaller.</p><p>75</p><p>But once a drug is available in a country for one specific thing, as we have seen, it can then be prescribed for absolutely anything. So it is not unusual for a drug to be licensed for use in adults, but then prescribed for children on the back of a hunch; or a judgement that it should at least do no harm; or studies that suggest benefit in children, but that would probably be insufficient to get through the specific formal process of getting marketing authorisation for use in kids; or even good studies, but in a disease where the market is so small that the company can’t be bothered to get a marketing approval for use in children.</p><p>76</p><p>Regulators have recognised that there is a serious problem with drugs being used in children ‘off-label’, without adequate research, so recently they have started to offer incentives for companies to conduct the research, and formally seek these licences. The incentives are patent extensions, and these can be lucrative. All drugs slip into the public domain about a decade after coming onto the market, and become like paracetamol, which anyone can make very cheaply. If a company is given a six-month extension on a drug, for all uses, then it can make a lot more money from that medicine. This seems a good example of regulators being pragmatic, and thinking creatively about what carrots they can offer. Licensed use in children will probably not itself make a company much extra money, since doctors are prescribing the drug for children already, even without a licence or good evidence, simply because there are no other options. Meanwhile, six months of extra patent life for a blockbuster drug will be very lucrative, if its adult market is large enough.</p><p>76</p><p>There’s a lot of debate about whether the drug companies have played fair with these offers. For example, since the FDA started offering this deal, about a hundred drugs have been given paediatric licences, but many of them were for diseases that aren’t very common in children, like stomach ulcers, or arthritis. There have been far fewer applications for less lucrative products that could be used in children, such as more modern medicines called ‘large-molecule biologics’. But there it is.</p><p>77</p><p>When GSK applied for a marketing authorisation in children for paroxetine, an extraordinary situation came to light, triggering the longest investigation in the history of UK drugs regulation. This investigation was published in 2008, and examined whether GSK should face criminal charges.64 It turned out that what the company had done – withholding important data about safety and effectiveness that doctors and patients clearly needed to see – was plainly unethical, and put children around the world at risk; but our laws are so weak that GSK could not be charged with any crime.</p><p>435</p><p>64 You can read the letters and the report online. It’s a gripping read, with many interesting and nefarious details, so I highly recommend doing so: Medicines and Healthcare products Regulatory Agency (MHRA)
<a href=https://www.mhra.gov.u rel=noopener>www.mhra.gov.u</a>. GSK investigation concludes [Internet]. [cited 2012 Apr 29]. Available from:
<a href=http://www.mhra.gov.uk/Howweregulate/Medicines/Medicinesregulatorynews/CON014153 rel=noopener>http://www.mhra.gov.uk/Howweregulate/Medicines/Medicinesregulatorynews/CON014153</a></p><p>77</p><p>Between 1994 and 2002 GSK conducted nine trials of paroxetine in children.65 The first two failed to show any benefit, but the company made no attempt to inform anyone of this by changing the ‘drug label’ that is sent to all doctors and patients. In fact, after these trials were completed, an internal company management document stated: ‘it would be commercially unacceptable to include a statement that efficacy had not been demonstrated, as this would undermine the profile of paroxetine’. In the year after this secret internal memo, 32,000 prescriptions were issued to children for paroxetine in the UK alone: so, while the company knew the drug didn’t work in children, it was in no hurry to tell doctors that, despite knowing that large numbers of children were taking it. More trials were conducted over the coming years – nine in total – and none showed that the drug was effective at treating depression in children.</p><p>435</p><p>65 This was SmithKline Beecham, before they merged with GlaxoWellcome and became GSK.</p><p>78</p><p>It gets much worse than that. These children weren’t simply receiving a drug that the company knew to be ineffective for them: they were also being exposed to side effects. This should be self-evident, since any effective treatment will have some side effects, and doctors factor this in, alongside the benefits (which in this case were non-existent). But nobody knew how bad these side effects were, because the company didn’t tell doctors, or patients, or even the regulator about the worrying safety data from its trials. This was because of a loophole: you only have to tell the regulator about side effects reported in studies looking at the specific uses for which the drug has a marketing authorisation. Because the use of paroxetine in children was ‘off-label’, GSK had no legal obligation to tell anyone about what it had found.</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li><a href=/Bad-Pharma-How-Drug-Companies-Mislead-Doctors-and-Harm-Patients/ data-ctx="Inbox scrap 31" data-src=/Bad-Pharma-How-Drug-Companies-Mislead-Doctors-and-Harm-Patients class=internal-link>Bad Pharma How Drug Companies Mislead Doctors and Harm Patients</a></li><li><a href=/Living-Thelema/ data-ctx="Inbox scrap 31" data-src=/Living-Thelema class=internal-link>Living Thelema</a></li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#D0A4FF}</style><script src=https://thecosmos.brycemcalister.com/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Bryce Mcalister using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://thecosmos.brycemcalister.com>Home</a></li><li><a href></a></li><li><a href></a></li></ul></footer></div></div></body></html>