485

2. IMS Health, “2007 top therapeutic classes by U.S. sales.”

20

There is one other, subtler aspect to this epidemic. Over the past twenty-five years, psychiatry has profoundly reshaped our society. Through its Diagnostic and Statistical Manual, psychiatry draws a line between what is “normal” and what is not. Our societal understanding of the human mind, which in the past arose from a medley of sources (great works of fiction, scientific investigations, and philosophical and religious writings), is now filtered through the DSM.

20

Indeed, the stories told by psychiatry about “chemical imbalances” in the brain have reshaped our understanding of how the mind works and challenged our conceptions of free will. Are we really the prisoners of our neurotransmitters?

20

Most important, our children are the first in human history to grow up under the constant shadow of “mental illness.” Not too long ago, goof-offs, cutups, bullies, nerds, shy kids, teachers’ pets, and any number of other recognizable types filled the schoolyard, and all were considered more or less normal. Nobody really knew what to expect from such children as adults. That was part of the glorious uncertainty of life—the goof-off in the fifth grade might show up at his high school’s twenty-year reunion as a wealthy entrepreneur, the shy girl as an accomplished actress. But today, children diagnosed with mental disorders—most notably, ADHD, depression, and bipolar illness—help populate the schoolyard. These children have been told that they have something wrong with their brains and that they may have to take psychiatric medications the rest of their lives, just like a “diabetic takes insulin.” That medical dictum teaches all of the children on the playground a lesson about the nature of human kind, and that lesson differs in a radical way from what children used to be taught.

95

5   
The Hunt for Chemical Imbalances

115

Antipsychotics, antidepressants, and other psychotropic drugs, he wrote, “create perturbations in neurotansmitter functions.” In response, the brain goes through a series of compensatory adaptations. If a drug blocks a neurotransmitter (as an antipsychotic does), the presynaptic neurons spring into hyper gear and release more of it, and the postsynaptic neurons increase the density of their receptors for that chemical messenger. Conversely, if a drug increases the synaptic levels of a neurotransmitter (as an antidepressant does), it provokes the opposite response: The presynaptic neurons decrease their firing rates and the postsynaptic neurons decrease the density of their receptors for the neurotransmitter. In each instance, the brain is trying to nullify the drug’s effects. “These adaptations,” Hyman explained, “are rooted in homeostatic mechanisms that exist, presumably, to permit cells to maintain their equilibrium in the face of alterations in the environment or changes in the internal milieu.”

116

However, after a period of time, these compensatory mechanisms break down. The “chronic administration” of the drug then causes “substantial and long-lasting alterations in neural function,” Hyman wrote. As part of this long-term adaptation process, there are changes in intracellular signaling pathways and gene expression. After a few weeks, he concluded, the person’s brain is functioning in a manner that is “qualitatively as well as quantitatively different from the normal state.”

116

what science had revealed was this: Prior to treatment, patients diagnosed with schizophrenia, depression, and other psychiatric disorders do not suffer from any known “chemical imbalance.” However, once a person is put on a psychiatric medication, which, in one manner or another, throws a wrench into the usual mechanics of a neuronal pathway, his or her brain begins to function, as Hyman observed, abnormally.

117

Thorazine, Miltown, and Marsilid were all derived from compounds that had been developed for other purposes—for use in surgery or as possible “magic bullets” against infectious diseases. Those compounds were then found to cause alterations in mood, behavior, and thinking that were seen as helpful to psychiatric patients. The drugs, in essence, were perceived as having beneficial side effects. They perturbed normal function, and that understanding was reflected in the initial names given to them.

117

psychiatry then reconceived the drugs as “magic bullets” for mental disorders, the drugs hypothesized to be antidotes to chemical imbalances in the brain. But that theory, which arose as much from wishful thinking as from science, was investigated and it did not pan out.

115

Today, as provost of Harvard University, Steve Hyman is mostly engaged in the many political and administrative tasks that come with leading a large institution. But he is a neuroscientist by training, and in 1996 to 2001, when he was the director of the NIMH, he wrote a paper, one both memorable and provocative in kind, that summed up all that had been learned about psychiatric drugs. Titled “Initiation and Adaptation: A Paradigm for Understanding Psychotropic Drug Action,” it was published in the American Journal of Psychiatry, and it told of how all psychotropic drugs could be understood to act on the brain in a common way.46

493

46. S. Hyman, “Initiation and adaptation: A paradigm for understanding psychotropic drug action,” American Journal of Psychiatry 153 (1996): 151–61.

110

once a presynaptic neuron has released serotonin into the synaptic gap, it must be quickly removed so that the signal can be crisply terminated. An enzyme metabolizes a small amount; the rest is pumped back into the presynaptic neuron, entering via a channel known as SERT (serotonin reuptake transport). Fluoxetine blocks this reuptake channel, and as a result, Eli Lilly scientist James Clemens wrote in 1975, it causes a “pile-up of serotonin at the synapse.”36

492

36. R. Fuller, “Effect of an uptake inhibitor on serotonin metabolism in rat brain,” Life Sciences 15 (1974): 1161–71.

110

However, as the Eli Lilly investigators discovered, a feedback mechanism then kicks in. The presynaptic neuron has “auto-receptors” on its terminal membrane that monitor the level of serotonin in the synapse. If serotonin levels are too low, one scientist quipped, these autoreceptors scream “turn on the serotonin machine.” If serotonin levels are too high, they scream “turn it off.” This is a feedback loop designed by evolution to keep the serotonergic system in balance, and fluoxetine triggers the latter message. With serotonin no longer being whisked away from the synapse, the autoreceptors tell the presynaptic neurons to fire at a dramatically lower rate. They begin to release lower-than-normal amounts of serotonin into the synapse.

110

Feedback mechanisms also change the postsynaptic neurons. Within four weeks, the density of their serotonin receptors drops 25 percent below normal, Eli Lilly scientists reported in 1981.37 Other investigators subsequently reported that “chronic fluoxetine treatment” may lead to a 50 percent reduction in serotonin receptors in certain areas of the brain.38 As a result, the post synaptic neurons become “desensitized” to the chemical messenger.

492

37. D. Wong, “Subsensitivity of serotonin receptors after long-term treatment of rats with fluoxetine,” Research Communications in Chemical Pathology and Pharmacology 32 (1981): 41–51.

492

38. J. Wamsley, “Receptor alterations associated with serotonergic agents,” Journal of Clinical Psychiatry 48, suppl. (1987): 19–25.

111

At this point, it may seem that the brain has successfully adapted to the drug. Fluoxetine blocks the normal reuptake of serotonin from the synapse, but the presynaptic neurons then begin releasing less serotonin and the postsynaptic neurons become less sensitive to serotonin and thus don’t fire so readily. The drug was designed to accelerate the serotonergic pathway; the brain responded by putting on the brake. It has kept its serotonergic pathway more or less in balance, an adaptive response that researchers have dubbed “synaptic resilience.”39 However, there is one other change that occurs during this initial two-week period, and it ultimately short-circuits the brain’s compensatory response. The autoreceptors for serotonin on the presynaptic neurons decline in number. As a result, this feedback mechanism becomes partially disabled, and the “turn off the serotonin machine” message dims. The presynaptic neurons begin to fire at a normal rate again, at least for a while, and to release more serotonin than normal each time. 40

492

40. C. Montigny, “Modification of serotonergic neuron properties by long-term treatment with serotonin reuptake blockers,” Journal of Clinical Psychiatry 51, suppl. B (1990): 4–8.

112

the Eli Lilly researchers reasoned in 1981 that it was the decline in serotonin receptors, which took several weeks to occur, that was “the underlying mechanism associated with the therapeutic response.”41 If so, the drug could be said to work because it drove the serotonergic system into a less responsive state. But once researchers discovered that fluoxetine partially disabled the feedback mechanism, Claude de Montigny at McGill University argued that this was what allowed the drug to begin working. This disabling process also took two or three weeks to occur, and it allowed the presynaptic neurons to begin pumping higher amounts of serotonin than normal into the synapse. At that point, with fluoxetine continuing to block serotonin’s removal, the neurotransmitter could now indeed “pile up” in the synapse, and that would lead “to an enhancement of central serotonergic neurotransmission,” de Montigny wrote.

493

41. D. Wong, “Subsensitivity of serotonin receptors after long-term treatment of rats with fluoxetine,” Research Communications in Chemical Pathology and Pharmacology 32 (1981): 41–51.

493

42. C. Montigny, “Modification of serotonergic neuron properties by long-term treatment with serotonin reuptake blockers,” Journal of Clinical Psychiatry 51, suppl. B (1990): 4–8.

113

the medicine clearly doesn’t fix a chemical imbalance in the brain. Instead, it does precisely the opposite. Prior to being medicated, a depressed person has no known chemical imbalance. Fluoxetine then gums up the normal removal of serotonin from the synapse, and that triggers a cascade of changes, and several weeks later the serotonergic pathway is operating in a decidedly abnormal manner. The presynaptic neuron is putting out more serotonin than usual. Its serotonin reuptake channels are blocked by the drug. The system’s feedback loop is partially disabled. The postsynaptic neurons are “desensitized” to serotonin. Mechanically speaking, the serotonergic system is now rather mucked up.

114

During the 1970s and 1980s, researchers studying the effects of neuroleptics fleshed out a similar story. Thorazine and other standard antipsychotics block 70 to 90 percent of all D2 receptors in the brain. In response, the presynaptic neurons begin pumping out more dopamine and the postsynaptic neurons increase the density of their D2 receptors by 30 percent or more. In this manner, the brain is trying to “compensate” for the drug’s effects so that it can maintain the transmission of messages along its dopaminergic pathways. However, after about three weeks, the pathway’s feedback mechanism begins to fail, and the presynaptic neurons begin to fire in irregular patterns or turn quiescent. It is this “inactivation” of dopaminergic pathways that “may be the basis for the antipsychotic action,” explains the American Psychiatric Association’s Textbook of Psychopharmacology.45

493

45. Schatzberg, Textbook of Psychopharmacology, 619.

114

Once again, this is a story of neurotransmitter pathways that have been transformed by the medication. After several weeks, their feedback loops are partially disabled, the presynaptic neurons are releasing less dopamine than normal, the drug is thwarting dopamine’s effects by blocking D2 receptors, and the postsynaptic neurons have an abnormally high density of these receptors. The drugs do not normalize brain chemistry, but disturb it,

107

This became the storytelling formula that was relied upon by pharmaceutical companies again and again: Researchers would identify the mechanism of action for a class of drugs, how the drugs either lowered or raised levels of a brain neurotransmitter, and soon the public would be told that people treated with those medications suffered from the opposite problem.

108

Psychopharmacology, was embraced by psychiatrists because it “set the stage” for them “to become real doctors.”31 Doctors in internal medicine had their antibiotics, and now psychiatrists could have their “anti-disease” pills too.

104

However, even as Snyder and Seeman were reporting their results, Malcolm Bowers was announcing findings that cast a cloud over the dopamine hypothesis. He had measured the level of dopamine metabolites in the cerebrospinal fluid of unmedicated schizophrenics and found them to be quite normal. “Our findings,” he wrote, “do not furnish neurochemical evidence for an over-arousal in these patients emanating from a midbrain dopamine system.”17 Others soon reported similar results. In 1975, Robert Post at the NIMH determined that HVA levels in the cerebrospinal fluid of twenty unmedicated schizophrenics “were not significantly different from controls.”18 Autopsy studies also revealed that the brain tissue of drug-free schizophrenics did not have abnormal levels of dopamine. In 1982, UCLA’s John Haracz reviewed this body of research and drew the obvious bottom-line conclusion: “These findings do not support the presence of elevated dopamine turnover in the brains of \[unmedicated\] schizophrenics.”19

491

17. M. Bowers, “Central dopamine turnover in schizophrenic syndromes,” Archives of General Psychiatry 31 (1974): 50–54.

491

18. R. Post, “Cerebrospinal fluid amine metabolites in acute schizophrenia,” Archives of General Psychiatry 32 (1975): 1063–68.

491

19. J. Haracz, “The dopamine hypothesis: an overview of studies with schizophrenic patients,” Schizophrenia Bulletin 8 (1982): 438–58.

105

Having discovered that dopamine levels in never-medicated schizophrenics were normal, researchers turned their attention to a second possibility. Perhaps people with schizophrenia had an overabundance of dopamine receptors. If so, the postsynaptic neurons would be “hypersensitive” to dopamine, and this would cause the dopaminergic pathways to be overstimulated. In 1978, Philip See-man at the University of Toronto announced in Nature that this was indeed the case. At autopsy, the brains of twenty schizophrenics had 70 percent more D2 receptors than normal. At first glance, it seemed that the cause of schizophrenia had been found, but Seeman cautioned that all of the patients had been on neuroleptics prior to their deaths. “Although these results are apparently compatible with the dopamine hypothesis of schizophrenia in general,” he wrote, the increase in D2 receptors might “have resulted from the long-term administration of neuroleptics.”20

491

20. T. Lee, “Binding of 3H-neuroleptics and 3H-apomorphine in schizophrenic brains,” Nature 374 (1978): 897–900.

105

A variety of studies quickly proved that the drugs were indeed the culprit. When rats were fed neuroleptics, their D2 receptors quickly increased in number.21 If rats were given a drug that blocked D1 receptors, that receptor subtype increased in density.22 In each instance, the increase was evidence of the brain trying to compensate for the drug’s blocking of its signals. Then, in 1982, Angus MacKay and his British colleagues reported that when they examined brain tissue from forty-eight deceased schizophrenics, “the increases in \[D2\] receptors were seen only in patients in whom neuroleptic medication had been maintained until the time of death, indicating that they were entirely iatrogenic \[drug-caused\].”23 A few years later, German investigators reported the same results from their autopsy studies.24 Finally, investigators in France, Sweden, and Finland used positron emission topography to study D2-receptor densities in living patients who had never been exposed to neuroleptics, and all reported “no significant differences” between the schizophrenics and “normal controls.”25

491

21. D. Burt, “Antischizophrenic drugs: chronic treatment elevates dopa mine receptor binding in brain,” Science 196 (1977): 326–27.

491

22. M. Porceddu, “\[3H\]SCH 23390 binding sites increase after chronic blockade of d-1 dopamine receptors,” European Journal of Pharmacology 118 (1985): 367–70.

491

23. A. MacKay, “Increased brain dopamine and dopamine receptors in schizophrenia,” Archives of General Psychiatry 39 (1982): 991–97.

491

24. J. Kornhuber, “3H-spiperone binding sites in post-mortem brains from schizophrenic patients,” Journal of Neural Transmission 75 (1989): 1–10.

491

25. J. Martinot, “Striatal D2 dopaminergic receptors assessed with positron emission tomography and bromospiperone in untreated schizophrenic patients,” American Journal of Psychiatry 147 (1990): 44–50; L. Farde, “D2 dopamine receptors in neuroleptic-naïve schizophrenic patients,” Archives of General Psychiatry 47 (1990): 213–19; J. Hietala, “Striatal D2 dopamine receptor characteristics in neuroleptic-naïve schizophrenic patients studied with positron emission tomography,” Archives of General Psychiatry 51 (1994): 116–23.

99

In a study of eight depressed patients (all of whom had been previously exposed to antidepressants), he announced that their 5-HIAA levels were lower than normal, but not “significantly” so.3 Two years later, investigators at McGill University said that they, too, had failed to find a “statistically significant” difference in the 5-HIAA levels of depressed patients and normal controls, and that they also had failed to find any correlation between 5-HIAA levels and the severity of depressive symptoms.4 In 1974, Bowers was back with a more finely tuned follow-up study: Depressed patients who had not been exposed to antidepressants had perfectly normal 5-HIAA levels.5

490

3. M. Bowers, “Cerebrospinal fluid 5-hydroxyindoleacetic acid and homovanillic acid in psychiatric patients,” International Journal of Neuropharmacology 8 (1969): 255–62.

490

4. R. Papeschi, “Homovanillic and 5-hydroxyindoleacetic acid in cerebrospinal fluid of depressed patients,” Archives of General Psychiatry 25 (1971): 354–58.

490

5. M. Bowers, “Lumbar CSF 5-hydroxyindoleacetic acid and homovanillic acid in affective syndromes,” Journal of Nervous and Mental Disease 158 (1974): 325–30.

100

It seemed that the theory was about to be declared dead and buried, but then, in 1975, Marie Asberg and her colleagues at the Karolinska Institute in Stockholm breathed new life into it. Twenty of the sixty-eight depressed patients they had tested suffered from low 5-HIAA levels, and these low-serotonin patients were somewhat more suicidal than the rest, with two of the twenty eventually committing suicide. This was evidence, the Swedish researchers said, that there might be “a biochemical subgroup of depressive disorder characterized by a disturbance of serotonin turnover.”8

Soon prominent psychiatrists in the United States were writing that “nearly 30 percent” of depressed patients had been found to have low serotonin levels. The serotonin theory of depression seemed at least partly vindicated.

490

8. M. Asberg, “Serotonin depression: A biochemical subgroup within the affective disorders?” Science 191 (1976): 478–80; M. Asberg, “5-HIAA in the cerebrospinal fluid,” Archives of General Psychiatry 33 (1976): 1193–97.

490

7. J. Mendels, “Brain biogenic amine depletion and mood,” Archives of General Psychiatry 30 (1974): 447–51.

490

6. D. L. Davies, “Reserpine in the treatment of anxious and depressed patients,” Lancet 2 (1955): 117–20.

100

But today, if we revisit Asberg’s study and examine her data, we can see that her finding of a “biological subgroup” of depressed patients was mostly a story of wishful thinking.

In her study, Asberg reported that 25 percent of her “normal” group had cerebrospinal 5-HIAA levels below fifteen nanograms per milliliter. Fifty percent had fifteen to twenty-five nanograms of 5-HIAA per milliliter, and the remaining 25 percent had levels above twenty-five nanograms. The bell curve for her “normals” showed that 5-HIAA levels were quite variable. But what she failed to note in her discussion was that the bell curve for the sixty-eight depressed patients in her study was almost exactly the same. Twenty-nine percent (twenty of the sixty-eight) had 5-HIAA counts below fifteen nanograms, 47 percent had levels between fifteen and twenty-five nanograms, and 24 percent had levels above twenty-five nanograms. Twenty-nine percent of depressed patients may have had “low” levels of serotonin metabolites in their cerebrospinal fluid (this was her “biological subgroup”), but then so did 25 percent of “normal” people. The median level for normals was twenty nanograms, and, it so turned out, more than half of the depressed patients—thirty-seven of sixty-eight—had levels above that amount.

101

Viewed in this way, her study had not provided any new reason to believe in the serotonin theory of depression. Japanese investigators soon revealed, in an unwitting way, the faulty logic at work. They reported that some antidepressants (used in Japan) blocked serotonin receptors, inhibiting the firing of those pathways, and thus they reasoned that depression might be caused by an “excess of free serotonin in the synaptic cleft.”9 They had applied the same backwards reasoning that had given rise to the low-serotonin theory of depression, and if the Japanese scientists had wanted to, they could have pointed to Asberg’s study for support of their theory, as the Swedes had found that 24 percent of depressed patients had “high” levels of serotonin.

490

9. H. Nagayama, “Postsynaptic action by four antidepressive drugs in an animal model of depression,” Pharmacology Biochemistry and Behavior 15 (1981): 125–30. Also see H. Nagayama, “Action of chronically administered antidepressants on the serotonergic postsynapse in a model of depression,” Pharmacology Biochemistry and Behavior 25 (1986): 805–11.

102

In 1984, NIMH investigators studied the low-serotonin theory of depression one more time. They wanted to see whether the “biological subgroup” of depressed patients with “low” levels of serotonin were the best responders to an antidepressant, amitriptyline, that selectively blocked its reuptake. If an antidepressant was an antidote to a chemical imbalance in the brain, then amitriptyline should be most effective in that subgroup. But, lead investigator James Maas wrote, “contrary to expectations, no relationships between cerebrospinal 5-HIAA and response to amitriptyline were found.”10 Moreover, he and the other NIMH researchers discovered—just as Asberg had—that 5-HIAA levels varied widely in depressed patients. Some had high levels of serotonin metabolites in their cerebrospinal fluid, while others had low levels. The NIMH scientists drew the only possible conclusion: “Elevations or decrements in the functioning of serotonergic systems per se are not likely to be associated with depression.”\*

490

10. J. Maas, “Pretreatment neurotransmitter metabolite levels and response to tricyclic antidepressant drugs,” American Journal of Psychiatry 141 (1984): 1159–71.

103

Even after this report, the serotonin theory of depression did not completely go away. The commercial success of Prozac, a “selective serotonin reuptake inhibitor” brought to market in 1988 by Eli Lilly, fueled a new round of public claims that depression was due to low levels of this neurotransmitter, and once again any number of investigators conducted experiments to see if that were so. But this second round of studies produced the same results as the first. “I spent the first several years of my career doing full-time research on brain serotonin metabolism, but I never saw any convincing evidence that any psychiatric disorder, including depression, results from a deficiency of brain serotonin,” said Stanford psychiatrist David Burns in 2003.11 Numerous others made this same point. “There is no scientific evidence whatsoever that clinical depression is due to any kind of biological deficit state,” wrote Colin Ross, an associate professor of psychiatry at Southwest Medical Center in Dallas, in his 1995 book, Pseudoscience in Biological Psychiatry.12 In 2000, the authors of Essential Psychopharmacology told medical students “there is no clear and convincing evidence that monoamine deficiency accounts for depression; that is, there is no ‘real’ monoamine deficit.”13 Yet, fueled by pharmaceutical advertisements, the belief lived on, and it caused Irish psychiatrist David Healy, who has written a number of books on the history of psychiatry, to quip in 2005 that this theory needed to be put into the medical dustbin, where other such discredited theories can be found. “The serotonin theory of depression,” he wrote, with evident exasperation, “is comparable to the masturbatory theory of insanity.”14

95

The mechanics of its messaging system are fairly well understood. There are, Cha noted, 100 billion neurons in the human brain. The cell body of a “typical” neuron receives input from a vast web of dendrites, and it sends out a signal via a single axon that may project to a distant area of the brain (or down the spinal cord). At its end, an axon branches into numerous terminals, and it is from these terminals that chemical messengers—dopamine, serotonin, etc.—are released into the synaptic cleft, which is a gap about twenty nanometers wide (a nanometer is one-billionth of a meter). A single neuron has between one thousand and ten thousand synaptic connections, with the adult brain as a whole having perhaps 150 trillion synapses.

96

The axons of neurons that use the same neurotransmitter are regularly bundled together, almost like the strands of a telecommunications cable, and once scientists discovered that dopamine, norepinephrine, and serotonin fluoresced different colors when exposed to formaldehyde vapors, it became possible to track those neurotransmitter pathways in the brain.

96

The serotonergic pathway is one with ancient evolutionary roots. Serotonergic neurons are found in the nervous systems of all vertebrates and most invertebrates, and in humans their cell bodies are located in the brain stem, in an area known as the raphe nuclei. Some of these neurons send long axons down the spinal cord, a system that is involved in the control of respiratory, cardiac, and gastrointestinal activities. Other serotonergic neurons have axons that ascend into all areas of the brain—the cerebellum, the hypothalamus, the basal ganglia, the temporal lobes, the limbic system, the cerebral cortex, and the frontal lobes. This pathway is involved in memory, learning, sleep, appetite, and the regulation of moods and behaviors. As Efrain Azmitia, a professor of biology at NYU, has noted, “the brain serotonin system is the single largest brain system known and can be characterized as a ‘giant’ neuronal system.”2

97

There are three major dopaminergic pathways in the brain. The cell bodies of all three systems are located atop the brain stem, in either the substantia nigra or the ventral tegmentum. Their axons project to the basal ganglia (nigrostriatal system), the limbic region (mesolimbic system), and the frontal lobes (mesocortical system). The basal ganglia initiates and controls movement. The limbic structures—the olfactory tubercle, the nucleus accumbens, and the amygdala, among others—are located behind the frontal lobes and help regulate our emotions. It is here that we feel the world, a process that is vital to our sense of self and our conceptions of reality. The frontal lobes are the most distinguishing feature of the human brain, and provide us with the godlike capacity to monitor our own selves.

97

All of this physiology—the 100 billion neurons, the 150 trillion synapses, the various neurotransmitter pathways—tell of a brain that is almost infinitely complex. Yet the chemical imbalance theory of mental disorders boiled this complexity down to a simple disease mechanism, one easy to grasp.

Aristotelian logic

97

In depression, the problem was that the serotonergic neurons released too little serotonin into the synaptic gap, and thus the serotonergic pathways in the brain were “underactive.” Antidepressants brought serotonin levels in the synaptic gap up to normal, and that allowed these pathways to transmit messages at a proper pace. Meanwhile, the hallucinations and voices that characterized schizophrenia resulted from overactive dopaminergic pathways. Either the presynaptic neurons pumped out too much dopamine into the synapse or the target neurons had an abnormally high density of dopamine receptors. Antipsychotics put a brake on this system, and this allowed the dopaminergic pathways to function in a more normal manner.

That was the chemical imbalance theory put forth by Schildkraut and Jacques Van Rossum,

98

and the very research that had led Schildkraut to his hypothesis also provided investigators with a method for testing it. The studies of iproniazid and imipramine had shown that neurotransmitters were removed from the synapse in one of two ways. Either the chemical was taken back up into the presynaptic neuron and restored for later use, or it was metabolized by an enzyme and carted off as waste. Serotonin is metabolized into 5-hydroxyindole acetic acid (5-HIAA); dopamine is turned into homo vanillic acid (HVA). Researchers could comb the cerebrospinal fluid for these metabolites, and the amounts found would serve as an indirect gauge of the synaptic levels of the neurotransmitters. Since low serotonin was theorized to cause depression, anyone in that emotional state should have lower-than-normal levels of 5-HIAA in his or her cerebrospinal fluid. Similarly, since an overactive dopamine system was theorized to cause schizophrenia, people who heard voices or were paranoid should have abnormally high cerebrospinal levels of HVA.

68

4   
Psychiatry’s Magic Bullets

78

Such were the drugs that launched the psychopharmacology revolution. In the short span of three years (1954–1957), psychiatry gained new medicines for quieting agitated and manic patients in asylums, for anxiety, and for depression. But none of these drugs had been developed after scientists had identified any disease process or brain abnormality that might have been causing these symptoms. They arrived out of the post–World War II search for magic bullets against infectious diseases, with researchers, during that process, stumbling on compounds that affected the central nervous system in novel ways. The animal tests of chlorpromazine, meprobamate, and chlordiazepoxide revealed that these agents sharply curbed normal physical and emotional responses, but did so without causing a loss of consciousness. That was what was so novel about the major and minor tranquilizers. They curbed brain function in a selective manner. It was unclear how iproniazid worked—it seemed to rev up the brain in some way—but, as the New York Times had noted, its mood-lifting properties were properly seen as a “side effect” of an anti-tuberculosis agent.

83

Miracle Pills

83

Smith Kline and French, which obtained a license from Rhône-Poulenc to sell chlorpromazine in the United States, secured FDA approval for Thorazine on March 26, 1954. A few days later, the company used its March of Medicine show to launch the product. Although Smith Kline and French had spent only $350,000 developing Thorazine, having administered it to fewer than 150 psychiatric patients prior to submitting its application to the FDA, the company’s president, Francis Boyer, told viewers that this was a product that had gone through the most rigorous testing imaginable. “It was administered to well over five thousand animals and proved active and safe for human administration,” he said. “We then placed the compound in the hands of physicians in our great American medical centers to explore its clinical value and possible limitations. In all, over two thousand doctors in this country and Canada have used it…. The development of a new medicine is difficult and costly, but it is a job our industry is privileged to perform.”21

83

Boyer’s was a story of rigorous science at work, and less than three months later, Time, in an article titled “Wonder Drug of 1954?,” pronounced Thorazine a “star performer.” After a dose of Thorazine, the magazine explained, patients “sit up and talk sense with \[the doctor\], perhaps for the first time in months.”22 In a follow-up article, Time reported that patients “willingly took \[the\] pills” and that once they did, they “fed themselves, ate heartily and slept well.” Thorazine, the magazine concluded, was as important “as the germ-killing sulfas discovered in the 1930s.”23

84

This was a magic-bullet reference that was impossible to miss, and other newspapers and magazines echoed that theme. Thanks to chlorpromazine, U.S. News and World Report explained, “patients who were formerly untreatable within a matter of weeks or months become sane, rational human beings.”24 The New York Times, in a series of articles in 1954 and 1955, called Thorazine a “miracle” pill that brought psychiatric patients “peace of mind” and “freedom from confusion.” Thorazine, newspapers and magazines agreed, had ushered in a “new era of psychiatry.”25

84

With such stories being told about Thorazine, it was little wonder that the public went gaga when Miltown, in the spring of 1955, was introduced into the market. This drug, Time reported, was for “walk-in neurotics rather than locked-in psychotics,” and according to what psychiatrists were telling newspaper and magazine reporters, it had amazing properties.26 Anxiety and worries fled so quickly, Changing Times explained, that it could be considered a “happy pill.” Reader’s Digest likened it to a “Turkish bath in a tablet.” The drug, explained Consumer Reports, “does not deaden or dull the senses, and it is not habit forming. It relaxes the muscles, calms the mind, and gives people a renewed ability to enjoy life.”27

86

There was one slightly hesitant note that appeared in newspaper and magazine articles during the introduction of Thorazine and Miltown. In the 1950s, many of the psychiatrists at top American medical schools were Freudians, who believed that mental disorders were caused by psychological conflicts, and their influence led Smith Kline and French, in its initial promotion of Thorazine, to caution reporters that “there is no thought that chlorpromazine is a cure for mental illness, but it can have great value if it relaxes patients and makes them accessible to treatment.”29 Both Thorazine and Miltown, explained the New York Times, should be considered as “adjuncts to psychotherapy, not the cure.”30

87

Yet, in very short order, even this note of caution went by the wayside. In 1957, the New York Times reported that researchers now believed that iproniazid might be a “potent regulator of unbalanced cerebral metabolism.”32 This suggested that the drug, which had been developed to fight tuberculosis, might be fixing something that was wrong in the brains of depressed patients.

87

psychiatrist Harold Himwich, in a 1958 article in Science, explained that they “may be compared with the advent of insulin, which counteracts symptoms of diabetes.”34 The antidepressants were fixing something wrong in the brain, and when Hoffmann-La Roche brought Librium to market in 1960, it picked up on this curative message. Its new drug was not just another tranquilizer, but rather “the successor to this entire group…. Librium is the biggest step yet toward ‘pure’ anxiety relief as distinct from central sedation or hypnotic action.”35 Merck did the same, marketing its drug Suavitil as “a mood normalizer…. Suavitil offers a new and specific type of neurochemical treatment for the patient who is disabled by anxiety, tension, depression, or obsessive-compulsive manifestations.”36

88

With this pronouncement by the NIMH, the transformation of the psychiatric drugs was basically complete. In the beginning, Thorazine and other neuroleptics had been viewed as agents that made patients quieter and emotionally indifferent. Now they were “antipsychotic” medications. Muscle relaxants that had been developed for use in psychiatry because of their “taming” properties were now “mood normalizers.” The psychic energizers were “antidepressants.” All of these drugs were apparently antidotes to specific disorders, and in that sense, they deserved to be compared to antibiotics. They were disease-fighting agents, rather than mere tonics. All that was missing from this story of magic-bullet medicine was an understanding of the biology of mental disorders, but with the drugs reconceived in this way, once researchers came to understand how the drugs affected the brain, they developed two hypotheses that, at least in theory, filled in this gap.

87

The final step in this image makeover of the psychiatric drugs came in 1963. The NIMH had conducted a six-week trial of Thorazine and other neuroleptics, and after these drugs were shown to be more effective than a placebo in knocking down psychotic symptoms, the researchers concluded that that the drugs should be regarded “as antischizophrenic in the broad sense. In fact, it is questionable whether the term ‘tranquilizer’ should be retained.”37

494

20. N. Schooler, “One year after discharge,” American Journal of Psychiatry 123 (1967): 986–95.

494

21. R. Prien, “Discontinuation of chemotherapy for chronic schizophrenics,” Hospital and Community Psychiatry 22 (1971): 20–23.

428

when we view the psychopharmacology “revolution” through this prism, as a business enterprise first and a medical enterprise second, we can easily see why psychiatry and the pharmaceutical companies tell the stories they do, and why the studies detailing poor long-term outcomes have been kept from the public. That information would derail a business enterprise that brings profits to so many.

428

As we saw earlier, during the late 1970s psychiatry was worried about its survival. The public viewed its therapies as “low in efficacy,” and sales of psychiatric drugs were in decline. Then, in what might be called a “rebranding” effort, psychiatry published DSM-III and began telling the public that mental disorders were “real” diseases, just like diabetes and cancer, and that their drugs were chemical antidotes to those diseases, just like “insulin for diabetes.” That story, while it may have been false in kind, created a powerful conceptual framework for selling psychiatric medications of all types. Everyone could understand the chemical-imbalance metaphor, and once the public came to understand that notion, it became relatively simple for pharmaceutical companies and their storytelling allies to build markets for psychiatric drugs of various types. They ran “educational” campaigns to make the public more “aware” of the various disorders the drugs were approved to treat, and, at the same time, they expanded the diagnostic boundaries of mental disorders.

429

After Prozac was introduced, NIMH’s DART campaign informed the public that depression regularly went “undiagnosed and untreated.” Upjohn partnered with the APA to tell the public that “panic disorder” was a common affliction. In 1990, the NIMH launched its “Decade of the Brain,” telling the public that 20 percent of Americans suffered from mental disorders (and thus might be in need of psychiatric medications). Soon psychiatric groups and others were promoting “screening programs,” which from a business perspective are best described as customer-recruitment efforts. NAMI, for its part, understood that its “educational” efforts served a commercial end, writing in a 2000 document filed with the government that “providers, health plans, and pharmaceutical companies want to grow their markets and to increase their share of the market…. NAMI will cooperate with these entities to grow the market by making persons aware of the issues involving severe brain disorders.”2

527

2. NAMI IRS 990 Form, 2000.

429

The APA is in charge of defining diagnostic categories in our society, and DSM-IV, an 886-page tome published in 1994, listed 297 disorders, 32 more than DSM-III. New and expanded diagnoses invite more people into the psychiatric drugstore, and one of the best examples of this type of market-building occurred in 1998, when GlaxoSmithKline got the FDA to approve Paxil for “social anxiety disorder.” In the past, this might have been perceived as a character trait (shyness), but GlaxoSmithKline hired a PR firm, Cohn & Wolfe, to promote awareness of this newly recognized “disease,” and soon newspapers and television shows were telling of how SAD afflicted 13 percent of the American population, making it “the third most common psychiatric disorder in the United States, after depression and alcoholism.” Those afflicted with this illness, the public learned, were in some ways biologically “allergic to people.”3

430

Diagnostic changes lay behind the bipolar boom, too. In DSM-III (1980), bipolar illness was identified for the first time (the old manic-depressive cohort was splintered into different groups), and then psychiatry steadily loosened the diagnostic boundaries for this illness, such that today the field talks about bipolar I, bipolar II, and a “bipolarity intermediate between bipolar disorder and normality.” This once rare disease is now said to afflict 1 to 2 percent of the adult population, and if the “intermediate” bipolar folk are counted, 6 percent. As this diagnostic expansion happened, pharmaceutical companies and their allies mounted their usual “educational” campaigns. Abbott Laboratories and NAMI teamed up to promote a “Bipolar Awareness Day;” in 2002, Eli Lilly joined with the Depression and Bipolar Support Alliance to launch a new online destination, bipolarawareness.com. Today many websites offer visitors a quick question-and-answer test to see if they have this illness.

431

Naturally, pharmaceutical companies want to sell their drugs to people of all ages, and they built the pediatric market for psychotropics step by step. First, in the 1980s, the prescribing of stimulants to “hyperactive” children took off. Next, in the early 1990s, psychiatrists began regularly prescribing SSRIs to teenagers. But that meant prepubertal children weren’t being prescribed these new wonder drugs, and in 1997, the Wall Street Journal reported that the manufacturers of SSRIs were “taking aim at a controversial new market: children.” The drug firms were “preparing their medications in easy-to-swallow forms that will be more palatable to even the youngest tykes,” the newspaper said, with Eli Lilly formulating a “minty liquid” Prozac for the tots to down.4 The New York Times, in its coverage of this initiative, explained quite clearly what was driving it: “The adult market for \[SSRIs\] has become saturated…. The companies are looking for expanded markets.”5 Psychiatry quickly provided a medical cover for this marketing effort, with the American Academy of Child and Adolescent Psychiatry announcing that 5 percent of all children in the United States were clinically depressed. “Many of these young patients now are inadequately treated, experts say, often leading to long-term emotional and behavioral problems, drug abuse, or even suicide,” the Wall Street Journal reported.6

432

The creation of the “juvenile bipolar” market was a bit more complicated. Prior to the 1990s, psychiatry thought that bipolar illness simply didn’t occur in prepubertal children, or was extremely rare. But children and teenagers prescribed stimulants and antidepressants often suffered manic episodes, and thus pediatricians and psychiatrists began to see more youth with “bipolar” symptoms. At the same time, once Janssen and Eli Lilly brought their atypical antipsychotics to market, they were looking for a way to sell those drugs to children, and during the mid-1990s, Joseph Biederman at Massachusetts General Hospital in Boston provided the diagnostic framework that made that possible. In 2009, while being deposed in a legal case, he explained his handiwork.

All psychiatric diagnoses, he said, “are subjective in children and in adults.” As such, he and his colleagues decided that children who in the past had been seen as having pronounced behavioral problems should instead be diagnosed with juvenile bipolar illness. “The conditions that we see in front of us are reconceptualized,” Biederman testified. “These children have been called in the past conduct disorder, oppositional-defiant disorder. It’s not that these children did not exist, they were just under different names.”7 Biederman and his colleagues decided that “severe irritability” or “affective storms” would be the telltale signs of juvenile bipolar disorder, and with this new diagnostic criteria in hand, they announced in 1996 that many children diagnosed with ADHD were in fact “bipolar” or else “comorbid” for both illnesses.8 The illness was a “much more common condition than was previously thought,” often appearing when children were only four or five years old, Biederman said.\* 9 Soon parents in the United States were reading newspaper articles about this newly recognized illness and buying The Bipolar Child, a book published by Random House in 2000. Child psychiatrists, meanwhile, began treating it with atypical antipsychotics.

433

That was the marketing machinery that lured more and more Americans into the psychiatric drugstore. As new drugs were brought to market, disease “awareness” campaigns were conducted and diagnostic categories were expanded. Now, once a business gets a customer into its store, it wants to keep that customer and get that customer to buy multiple products, and that’s when the psychiatric “drug trap” kicks in.

433

The “broken brain” story helps with customer retention, of course, for if a person suffers a “chemical imbalance,” then it makes sense that he or she will have to take the medication to correct it indefinitely, like “insulin for diabetes.” But more important, the drugs create chemical imbalances in the brain, and this helps turn a first-time customer into a long-term user, and often into a buyer of multiple drugs. The patient’s brain adapts to the first drug, and that makes it difficult to go off the medication. The store’s exit door is hard to squeeze through, so to speak. At the same time, since psychiatric drugs perturb normal function, they regularly cause physical and psychiatric problems, and this greases the path to polypharmacy. The hyperactive child is put on a stimulant that rouses him during the day; at night he needs a sleeping pill to go to sleep. An atypical causes people to feel depressed and lethargic; psychiatrists may prescribe an antidepressant to treat that problem. Conversely, an antidepressant may stir a bout of mania; in that case an atypical antipsychotic may be prescribed to tamp down the mania. The first drug triggers a need for a second, and so on.

Eli Lilly even capitalized on this fact when it brought Zyprexa to market. As it well knew, Prozac and other SSRIs could trigger manic episodes, and so it instructed its sales representatives to tell psychiatrists that Zyprexa “is a great mood stabilizer, especially for patients whose symptoms were aggravated by an SSRI.”10 In essence, Eli Lilly was telling doctors to prescribe its second drug to fix the psychiatric problems caused by its first one. We can also see this cascading effect operating at a societal level. The SSRIs came to market and suddenly bipolar patients were cropping up everywhere, and then this new group of patients provided a market for the atypicals.\*

434

All of this has produced a growth industry of impressive dimensions. In 1985, outpatient sales of antidepressants and antipsychotics in the United States amounted to $503 million.11 Twenty-three years later, U.S. sales of antidepressants and anti psychotics reached $24.2 billion, nearly a fiftyfold increase. Anti psychotics—a class of drugs previously seen as extremely problematic in kind, useful only in severely ill patients—were the top revenue-producing class of drugs in 2008, ahead even of the cholesterol-lowering agents.12 Total sales of all psychotropic drugs in 2008 topped $40 billion. Today—and this shows how crowded the drugstore has become—one in every eight Americans takes a psychiatric drug on a regular basis.13

527

11. J. J. Zorc, “Expenditures for psychotropic medications in the United States in 1985,” American Journal of Psychiatry 148 (1991): 644–47

527

12. “Top therapeutic classes by U.S. sales, 2008,” IMS Health.

527

13. S. Giled, “Better but not best,” Health Affairs 28 (2009): 637–48.

443

According to a 2009 report by the federal Agency for Healthcare Research and Quality, spending on mental health services is now rising at a faster rate than for any other medical category.29 In 2008, the United States spent about $170 billion on mental health services, which is twice the amount it spent in 2001, and this spending is projected to increase to $280 billion in 2015. The public, primarily through its Medicaid and Medicare programs, picks up close to 60 percent of the nation’s spending on mental health services.30

528

29. E. Mundell, “U.S. spending on mental health care soaring,” HealthDay, August 6, 2009.

528

30. T. Mark, “Mental health treatment expenditure trends, 1986–2003,” Psychiatric Services 58 (2007): 1041–48. Seven percent of national health expenditures in 2008 went to mental health services; by 2015, this figure is expected to rise to 8 percent. Data on national health expenditures in 2008, and projected expenditures in 2015, are from the U.S. Department of Health and Human Services.

383

14  
The Story That Was … and Wasn’t Told
